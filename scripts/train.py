#!/usr/bin/env python3
# scripts/train.py

"""
FinFlow-RL ë©”ì¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
IQL ì‚¬ì „í•™ìŠµ â†’ Distributional SAC ì˜¨ë¼ì¸ í•™ìŠµ
"""

import argparse
import yaml
import os
import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

import torch
import numpy as np
import pandas as pd
from tqdm import tqdm

from src.utils.seed import set_seed, DeviceManager
from src.utils.logger import FinFlowLogger, get_session_directory
from src.data.loader import DataLoader
from src.data.loader import FeatureExtractor
from src.core.env import PortfolioEnv
from src.core.objectives import PortfolioObjective, RewardNormalizer
from src.core.trainer import FinFlowTrainer, TrainingConfig

def load_config(config_path: str) -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def main():
    parser = argparse.ArgumentParser(description='FinFlow-RL Training')
    parser.add_argument('--config', type=str, default='configs/default.yaml',
                       help='Path to config file')
    parser.add_argument('--resume', type=str, default=None,
                       help='Path to checkpoint to resume from')
    parser.add_argument('--debug', action='store_true',
                       help='Debug mode with verbose output')
    parser.add_argument('--mode', type=str, default='full', choices=['full', 'iql', 'sac'],
                       help='Training mode: full (IQL+SAC), iql (only), or sac (only)')
    parser.add_argument('--use-trainer', action='store_true', default=True,
                       help='Use integrated trainer (default: True)')
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = load_config(args.config)
    
    # í†µí•© Trainer ì‚¬ìš© (ê¶Œì¥)
    if args.use_trainer:
        logger = FinFlowLogger("Main")
        logger.info("=" * 80)
        logger.info("FinFlow-RL (BIPD 2.0) í†µí•© í•™ìŠµ ì‹œì‘")
        logger.info("=" * 80)
        logger.info(f"ì„¤ì • íŒŒì¼: {args.config}")
        logger.info(f"í•™ìŠµ ëª¨ë“œ: {args.mode}")
        
        # TrainingConfig ìƒì„±
        training_config = TrainingConfig(
            # Environment
            env_config={
                'initial_balance': config['env']['initial_capital'],
                'transaction_cost': config['env']['turnover_cost'],
                'max_leverage': config['env']['max_leverage'],
                'window_size': config['features']['window']
            },
            # Data
            data_config={
                'tickers': config['data']['symbols'],
                'period': '5y',  # 5ë…„ ë°ì´í„°
                'interval': '1d',
                'auto_download': True,
                'use_cache': True
            },
            # IQL
            iql_epochs=config['train']['offline_steps'] // 1000,
            iql_batch_size=config['train']['offline_batch_size'],
            iql_expectile=config['bcell']['iql_expectile'],
            iql_temperature=config['bcell']['iql_temperature'],
            # SAC
            sac_episodes=config['train']['online_steps'] // 100,
            sac_batch_size=config['train']['online_batch_size'],
            sac_gamma=config['bcell']['gamma'],
            sac_tau=config['bcell']['tau'],
            sac_alpha=config['bcell']['alpha_init'],
            sac_cql_weight=config['bcell']['cql_alpha_start'],
            # Memory
            memory_capacity=config['train']['buffer_size'],
            memory_k_neighbors=config['memory']['k_neighbors'],
            # Monitoring
            eval_interval=config['train']['eval_interval'] // 100,
            checkpoint_interval=config['train']['save_interval'] // 100,
            log_interval=config['train']['log_interval'] // 100,
            # Target metrics
            target_sharpe=config['objectives']['sharpe_beta'] * 1.5,
            target_cvar=config['objectives']['cvar_target'],
            # Device & Seed
            device=config['device'],
            seed=config['seed'],
            # Paths
            data_path='data/processed',
            checkpoint_dir='checkpoints'
        )
        
        # Trainer ìƒì„±
        trainer = FinFlowTrainer(training_config)
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (ìˆì„ ê²½ìš°)
        if args.resume:
            trainer.load_checkpoint(args.resume)
            logger.info(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {args.resume}")
        
        # í•™ìŠµ ì‹¤í–‰
        if args.mode == 'full':
            trainer.train()  # IQL + SAC
        elif args.mode == 'iql':
            trainer._pretrain_iql()  # IQLë§Œ
        elif args.mode == 'sac':
            trainer._train_sac()  # SACë§Œ
        
        logger.info("\nğŸ‰ FinFlow-RL í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return
    
    # Trainerë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ê²½ê³ 
    logger = FinFlowLogger("Training")
    logger.error("=" * 80)
    logger.error("ê²½ê³ : í†µí•© Trainerë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤!")
    logger.error("--use-trainer ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ê°•í™”í•™ìŠµì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    logger.error("=" * 80)
    logger.info("\nì‚¬ìš©ë²•:")
    logger.info("  python scripts/train.py --use-trainer --mode full")
    logger.info("  python scripts/train.py --use-trainer --mode iql  # IQLë§Œ")
    logger.info("  python scripts/train.py --use-trainer --mode sac  # SACë§Œ")
    return
    
    # ë” ì´ìƒ ëœë¤ ì •ì±… í…ŒìŠ¤íŠ¸ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
    # ì‹¤ì œ ê°•í™”í•™ìŠµì€ Trainerë¥¼ í†µí•´ì„œë§Œ ìˆ˜í–‰

if __name__ == "__main__":
    main()