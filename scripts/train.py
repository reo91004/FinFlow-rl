#!/usr/bin/env python3
# scripts/train.py

"""
FinFlow-RL ë©”ì¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
IQL ì‚¬ì „í•™ìŠµ â†’ Distributional SAC ì˜¨ë¼ì¸ í•™ìŠµ
"""

import argparse
import yaml
import os
import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

import torch
import numpy as np
import pandas as pd
from tqdm import tqdm

from src.utils.device_manager import set_seed, DeviceManager
from src.utils.logger import FinFlowLogger, get_session_directory
from src.data import DataLoader, FeatureExtractor
from src.environments.portfolio_env import PortfolioEnv
from src.environments.reward_functions import PortfolioObjective, RewardNormalizer
from src.training.trainer import FinFlowTrainer

def load_config(config_path: str) -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def main():
    parser = argparse.ArgumentParser(description='FinFlow-RL Training')
    parser.add_argument('--config', type=str, default='configs/default.yaml',
                       help='Path to config file')
    parser.add_argument('--resume', type=str, default=None,
                       help='Path to checkpoint to resume from')
    parser.add_argument('--debug', action='store_true',
                       help='Debug mode with verbose output')
    parser.add_argument('--mode', type=str, default='full', choices=['full', 'offline', 'online'],
                       help='Training mode: full (Offline+Online), offline (IQL/TD3BC), or online (REDQ/TQC)')
    parser.add_argument('--use-trainer', action='store_true', default=True,
                       help='Use integrated trainer (default: True)')
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = load_config(args.config)
    
    # í†µí•© Trainer ì‚¬ìš© (ê¶Œì¥)
    if args.use_trainer:
        logger = FinFlowLogger("Main")
        logger.info("=" * 80)
        logger.info("FinFlow-RL (BIPD 2.0) í†µí•© í•™ìŠµ ì‹œì‘")
        logger.info("=" * 80)
        logger.info(f"ì„¤ì • íŒŒì¼: {args.config}")
        logger.info(f"í•™ìŠµ ëª¨ë“œ: {args.mode}")
        
        # Trainer ìƒì„± (configë¥¼ ì§ì ‘ ì „ë‹¬)
        trainer = FinFlowTrainer(config)
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (ìˆì„ ê²½ìš°)
        if args.resume:
            trainer.load_checkpoint(args.resume)
            logger.info(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {args.resume}")
        
        # í•™ìŠµ ì‹¤í–‰
        if args.mode == 'full':
            trainer.train()  # IQL + Online (REDQ/TQC)
        elif args.mode == 'offline':
            trainer._offline_pretrain()  # ì˜¤í”„ë¼ì¸ í•™ìŠµë§Œ (IQL/TD3BC)
        elif args.mode == 'online':
            trainer._online_finetune()  # Online í•™ìŠµë§Œ (REDQ/TQC)
        
        logger.info("\nğŸ‰ FinFlow-RL í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return
    
    # Trainerë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ê²½ê³ 
    logger = FinFlowLogger("Training")
    logger.error("=" * 80)
    logger.error("ê²½ê³ : í†µí•© Trainerë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤!")
    logger.error("--use-trainer ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ê°•í™”í•™ìŠµì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    logger.error("=" * 80)
    logger.info("\nì‚¬ìš©ë²•:")
    logger.info("  python scripts/train.py --use-trainer --mode full")
    logger.info("  python scripts/train.py --use-trainer --mode offline  # ì˜¤í”„ë¼ì¸ í•™ìŠµ (IQL/TD3BC)")
    logger.info("  python scripts/train.py --use-trainer --mode online  # Online (REDQ/TQC)")
    return
    
    # ë” ì´ìƒ ëœë¤ ì •ì±… í…ŒìŠ¤íŠ¸ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
    # ì‹¤ì œ ê°•í™”í•™ìŠµì€ Trainerë¥¼ í†µí•´ì„œë§Œ ìˆ˜í–‰

if __name__ == "__main__":
    main()