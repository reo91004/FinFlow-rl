# IRT (Immune Replicator Transport) ì„¤ëª…ì„œ

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ë‚´ë¶€ ì•„í‚¤í…ì²˜](#ë‚´ë¶€-ì•„í‚¤í…ì²˜)
3. [IRTì˜ 3ê°€ì§€ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜](#irtì˜-3ê°€ì§€-í•µì‹¬-ë©”ì»¤ë‹ˆì¦˜)
4. [íš¨ê³¼ ë° ì„±ëŠ¥ ëª©í‘œ](#íš¨ê³¼-ë°-ì„±ëŠ¥-ëª©í‘œ)
5. [ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ê³¼ì˜ ë¹„êµ](#ë‹¤ë¥¸-ì•Œê³ ë¦¬ì¦˜ê³¼ì˜-ë¹„êµ)
6. [í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì´ë“œ](#í•˜ì´í¼íŒŒë¼ë¯¸í„°-ê°€ì´ë“œ)
7. [ì‚¬ìš© ì˜ˆì‹œ](#ì‚¬ìš©-ì˜ˆì‹œ)
8. [ì°¸ê³  ë¬¸í—Œ](#ì°¸ê³ -ë¬¸í—Œ)

---

## ê°œìš”

### IRTë€ ë¬´ì—‡ì¸ê°€?

IRT (Immune Replicator Transport)ëŠ” **ë©´ì—­í•™ì  ë©”ì»¤ë‹ˆì¦˜ì—ì„œ ì˜ê°ì„ ë°›ì€** í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. ì‹œì¥ ìœ„ê¸° ìƒí™©ì—ì„œ ì ì‘ë ¥ì„ ë†’ì´ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ë‘ ê°€ì§€ ì„œë¡œ ë‹¤ë¥¸ ì „ëµì„ í˜¼í•©í•œë‹¤:

1. **ê³¼ê±° ì„±ê³µ ê²½í—˜ í™œìš©** (Replicator Dynamics)
2. **í˜„ì¬ ìƒí™©ì— ë§ëŠ” ì „ëµ íƒìƒ‰** (Optimal Transport)

### í•µì‹¬ ê³µì‹

```
w_t = (1-Î±)Â·Replicator(w_{t-1}, f_t) + Î±Â·Transport(E_t, K, C_t)
```

**í•´ì„**:
- `w_t`: í˜„ì¬ ì‹œì ì˜ í”„ë¡œí† íƒ€ì… í˜¼í•© ê°€ì¤‘ì¹˜
- `Î±`: OT-Replicator í˜¼í•© ë¹„ìœ¨ (0~1 ì‚¬ì´, ê¸°ë³¸ 0.3)
- `Replicator(w_{t-1}, f_t)`: ê³¼ê±° ì„±ê³µ ì „ëµì— ê¸°ë°˜í•œ ê°€ì¤‘ì¹˜
- `Transport(E_t, K, C_t)`: í˜„ì¬ ìƒíƒœì— ìµœì í™”ëœ ê°€ì¤‘ì¹˜

### ì™œ ìœ„ê¸° ì ì‘ì— íš¨ê³¼ì ì¸ê°€?

ì¼ë°˜ì ì¸ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì€ **ë‹¨ì¼ ì •ì±…**ì„ í•™ìŠµí•œë‹¤. í•˜ì§€ë§Œ ê¸ˆìœµ ì‹œì¥ì€ **ì •ìƒ êµ¬ê°„**ê³¼ **ìœ„ê¸° êµ¬ê°„**ì—ì„œ ì™„ì „íˆ ë‹¤ë¥¸ íŠ¹ì„±ì„ ë³´ì¸ë‹¤:

- **ì •ìƒ êµ¬ê°„**: ë‚®ì€ ë³€ë™ì„±, ì˜ˆì¸¡ ê°€ëŠ¥í•œ íŒ¨í„´
- **ìœ„ê¸° êµ¬ê°„**: ë†’ì€ ë³€ë™ì„±, ê¸‰ê²©í•œ ë³€í™”, ìƒê´€ê´€ê³„ ë¶•ê´´

IRTëŠ” **ì—¬ëŸ¬ ì „ë¬¸ê°€ ì „ëµ(í”„ë¡œí† íƒ€ì…)**ì„ í•™ìŠµí•˜ê³ , í˜„ì¬ ìƒí™©ì— ë”°ë¼ ë™ì ìœ¼ë¡œ í˜¼í•©í•œë‹¤:

```
ìœ„ê¸° ê°ì§€ â†’ T-Cellì´ ìœ„ê¸° ë ˆë²¨ ì¶œë ¥
         â†’ Replicator ê°€ì—´ (ë¹ ë¥¸ ì ì‘)
         â†’ OTê°€ ìœ„ê¸° ì‹ í˜¸ì™€ ì •ë ¬ëœ í”„ë¡œí† íƒ€ì… ì„ íƒ
         â†’ ìœ„ê¸° ì ì‘í˜• í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
```

---

## ë‚´ë¶€ ì•„í‚¤í…ì²˜

### Stable Baselines3 í†µí•© êµ¬ì¡°

IRTëŠ” Stable Baselines3ì˜ SAC ì•Œê³ ë¦¬ì¦˜ê³¼ í†µí•©í•˜ì—¬ ì‘ë™í•œë‹¤. ë‹¤ìŒì€ ì „ì²´ ì•„í‚¤í…ì²˜ íë¦„ì´ë‹¤:

```
SAC.train()
  â”‚
  â”œâ”€> policy.predict(obs, deterministic)
  â”‚    â”‚
  â”‚    â””â”€> IRTPolicy._predict(obs)
  â”‚         â”‚
  â”‚         â””â”€> IRTActorWrapper.forward(obs, deterministic)
  â”‚              â”‚
  â”‚              â”œâ”€> obs.float()  # dtype ë³€í™˜ (float64 â†’ float32)
  â”‚              â”‚
  â”‚              â”œâ”€> _compute_fitness(obs)  # Critic ê¸°ë°˜ fitness ê³„ì‚°
  â”‚              â”‚    â”‚
  â”‚              â”‚    â”œâ”€> ê° í”„ë¡œí† íƒ€ì… jì˜ ìƒ˜í”Œ í–‰ë™ ìƒì„±
  â”‚              â”‚    â”‚    â””â”€> decoders[j](proto_keys[j]) â†’ conc_j â†’ softmax â†’ a_j
  â”‚              â”‚    â”‚
  â”‚              â”‚    â””â”€> Critic Q-value ê³„ì‚° (Twin Q ìµœì†Œê°’)
  â”‚              â”‚         â””â”€> critic(obs, a_j) â†’ fitness[j]
  â”‚              â”‚
  â”‚              â””â”€> BCellIRTActor(state=obs, fitness=fitness, deterministic)
  â”‚                   â”‚
  â”‚                   â”œâ”€> Step 1: T-Cell ìœ„ê¸° ê°ì§€
  â”‚                   â”‚    â”œâ”€> Market features ì¶”ì¶œ (12ì°¨ì›):
  â”‚                   â”‚    â”‚    â”œâ”€ ì‹œì¥ í†µê³„: balance, price_mean, price_std, cash_ratio
  â”‚                   â”‚    â”‚    â””â”€ Tech indicators: macd, boll_ub, boll_lb, rsi_30, cci_30, dx_30, sma_30, sma_60
  â”‚                   â”‚    â””â”€> TCellMinimal(market_features) â†’ crisis_level, danger_embed
  â”‚                   â”‚
  â”‚                   â”œâ”€> Step 2: Epitope ì¸ì½”ë”©
  â”‚                   â”‚    â””â”€> epitope_encoder(state) â†’ E [B, m, D]
  â”‚                   â”‚
  â”‚                   â”œâ”€> Step 3: Prototype í™•ì¥
  â”‚                   â”‚    â””â”€> proto_keys â†’ K [B, M, D]
  â”‚                   â”‚
  â”‚                   â”œâ”€> Step 4: IRT ì—°ì‚°
  â”‚                   â”‚    â””â”€> IRT(E, K, danger, w_prev, fitness, crisis) â†’ w, P
  â”‚                   â”‚         â”‚
  â”‚                   â”‚         â”œâ”€> Sinkhorn (OT) â†’ w_ot
  â”‚                   â”‚         â””â”€> Replicator Dynamics(fitness) â†’ w_rep  # âœ… fitness ì‚¬ìš©
  â”‚                   â”‚         â””â”€> Mixing: w = (1-Î±)Â·w_rep + Î±Â·w_ot
  â”‚                   â”‚
  â”‚                   â”œâ”€> Step 5: Projected Gaussian ì •ì±… (Phase 1.7)
  â”‚                   â”‚    â””â”€> mu_decoders[j](K), log_std_decoders[j](K) â†’ mus, log_stds
  â”‚                   â”‚    â””â”€> mixed_mu = w @ mus, mixed_std = w @ stds
  â”‚                   â”‚    â””â”€> z = mixed_mu + ÎµÂ·mixed_std (Gaussian ìƒ˜í”Œë§)
  â”‚                   â”‚    â””â”€> action = proj_simplex(z) (Euclidean Projection)
  â”‚                   â”‚    â””â”€> log_prob = log N(z|Î¼,ÏƒÂ²) (no Jacobian)
  â”‚                   â”‚
  â”‚                   â””â”€> Step 6: EMA ì—…ë°ì´íŠ¸ (w_prev)
  â”‚                        â””â”€> w_prev = Î²Â·w_prev + (1-Î²)Â·w.mean()
  â”‚
  â””â”€> policy.actor.action_log_prob(obs)
       â”‚
       â””â”€> IRTActorWrapper.action_log_prob(obs)
            â”‚
            â”œâ”€> obs.float()  # dtype ë³€í™˜
            â”‚
            â”œâ”€> _compute_fitness(obs)  # ë™ì¼í•œ helper ì‚¬ìš©
            â”‚
            â””â”€> BCellIRTActor(state=obs, fitness=fitness, deterministic=False)  # í•œ ë²ˆë§Œ í˜¸ì¶œ!
                 â”‚
                 â””â”€> (action, log_prob, info) ë°˜í™˜ (log_probì€ ì´ë¯¸ ê³„ì‚°ë¨)
```

### ë ˆì´ì–´ë³„ ì—­í• 

#### 1. IRTPolicy (SACPolicy ìƒì†)

**ì—­í• **: SB3ì˜ ì •ì±… ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•œë‹¤.

**ì£¼ìš” ë©”ì„œë“œ**:
- `make_actor()`: IRT Actorë¥¼ ìƒì„± (SACPolicy ë©”ì„œë“œ override)
- `_get_constructor_parameters()`: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ìš© íŒŒë¼ë¯¸í„°

**ì™œ SACPolicyë¥¼ ìƒì†í•˜ëŠ”ê°€?**
- SACëŠ” `policy.actor`ë¥¼ í†µí•´ Actorì— ì ‘ê·¼í•¨
- `make_actor()`ë¥¼ overrideí•˜ì—¬ IRT Actorë¥¼ ì£¼ì…
- Criticì€ SB3 ê¸°ë³¸ ì‚¬ìš© (IRTëŠ” Actorë§Œ êµì²´)

#### 2. IRTActorWrapper (Actor ì¸í„°í˜ì´ìŠ¤)

**ì—­í• **: BCellIRTActorë¥¼ SACê°€ ê¸°ëŒ€í•˜ëŠ” Actor ì¸í„°í˜ì´ìŠ¤ë¡œ wrappingí•œë‹¤.

**ì£¼ìš” ë©”ì„œë“œ**:
- `_compute_fitness(obs)`: Critic ê¸°ë°˜ fitness ê³„ì‚° (helper method)
- `forward(obs, deterministic)`: mean actions ë°˜í™˜
- `action_log_prob(obs)`: actionê³¼ log_prob ë°˜í™˜
- `get_std()`: standard deviation ë°˜í™˜ (gSDEìš©, IRTëŠ” ë¯¸ì‚¬ìš©)

**ì™œ Wrapperê°€ í•„ìš”í•œê°€?**
- SACëŠ” `actor.action_log_prob(obs)`ë¥¼ í˜¸ì¶œí•¨
- BCellIRTActorëŠ” `(state, fitness, deterministic)` ì‹œê·¸ë‹ˆì²˜ë¥¼ ì‚¬ìš©
- Wrapperê°€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë³€í™˜í•˜ê³ , IRTë¥¼ **í•œ ë²ˆë§Œ** í˜¸ì¶œí•˜ë„ë¡ ë³´ì¥

**í•µì‹¬ ìµœì í™” (Phase 1.4)**:
```python
# _compute_fitness() helper method (ê³µí†µ ë¡œì§)
def _compute_fitness(self, obs):
    # ê° í”„ë¡œí† íƒ€ì…ì˜ Q-value ê³„ì‚°
    for j in range(M):
        a_j = softmax(decoders[j](proto_keys[j]))
        fitness[j] = min(critic(obs, a_j))  # Twin Q ìµœì†Œê°’
    return fitness

# forward()ì™€ action_log_prob() ëª¨ë‘ helper ì‚¬ìš©
def forward(self, obs, deterministic):
    obs = obs.float()  # dtype ë³€í™˜
    fitness = self._compute_fitness(obs)  # âœ… Critic ê¸°ë°˜
    action, info = self.irt_actor(state=obs, fitness=fitness, deterministic=deterministic)
    return action

def action_log_prob(self, obs):
    obs = obs.float()  # dtype ë³€í™˜
    fitness = self._compute_fitness(obs)  # âœ… ë™ì¼í•œ helper
    action, info = self.irt_actor(state=obs, fitness=fitness, deterministic=False)

    # infoì—ì„œ concentration ì¬ì‚¬ìš©
    mixed_conc_clamped = info['mixed_conc_clamped']
    dist = torch.distributions.Dirichlet(mixed_conc_clamped)
    log_prob = dist.log_prob(action)
    return action, log_prob
```

**ì£¼ìš” ê°œì„ ì‚¬í•­**:
- âœ… **dtype ì•ˆì •ì„±**: `obs.float()` ë³€í™˜ìœ¼ë¡œ float64 â†’ float32
- âœ… **Train-Eval ì¼ê´€ì„±**: ë‘˜ ë‹¤ Critic ê¸°ë°˜ fitness ì‚¬ìš©
- âœ… **ì½”ë“œ ì¤‘ë³µ ì œê±°**: `_compute_fitness()` helperë¡œ DRY principle ì¤€ìˆ˜
- âœ… **IRT í•œ ë²ˆë§Œ í˜¸ì¶œ**: EMA ë©”ëª¨ë¦¬ (`w_prev`) ë³´ì¡´

#### 3. BCellIRTActor (IRT êµ¬í˜„)

**ì—­í• **: IRT ì•Œê³ ë¦¬ì¦˜ì˜ í•µì‹¬ êµ¬í˜„ì²´.

**ì£¼ìš” ì»´í¬ë„ŒíŠ¸**:
- `epitope_encoder`: ìƒíƒœ â†’ ë‹¤ì¤‘ í† í° (E)
- `proto_keys`: í•™ìŠµ ê°€ëŠ¥í•œ í”„ë¡œí† íƒ€ì… í‚¤ (K)
- `decoders`: í”„ë¡œí† íƒ€ì…ë³„ Dirichlet ë””ì½”ë”
- `irt`: IRT Operator (Sinkhorn + Replicator)
- `t_cell`: T-Cell ìœ„ê¸° ê°ì§€
- `w_prev`: EMA ë©”ëª¨ë¦¬ (buffer)

**Info êµ¬ì¡°** (v1.6ë¶€í„° Gaussian+Softmax):
```python
info = {
    'w': w,                          # [B, M] - ìµœì¢… í”„ë¡œí† íƒ€ì… ê°€ì¤‘ì¹˜
    'P': P,                          # [B, m, M] - ìˆ˜ì†¡ ê³„íš
    'crisis_level': crisis_level,    # [B, 1] - ìœ„ê¸° ë ˆë²¨
    'w_rep': w_rep,                  # [B, M] - Replicator ì¶œë ¥
    'w_ot': w_ot,                    # [B, M] - OT ì¶œë ¥
    # v1.6 ì¶”ê°€: Gaussian+Softmax ì •ì±… ì •ë³´
    'mu': mixed_mu,                  # [B, A] - í˜¼í•©ëœ Gaussian mean
    'std': mixed_std,                # [B, A] - í˜¼í•©ëœ Gaussian std
    'z': z,                          # [B, A] - Gaussian ìƒ˜í”Œ
    'log_prob_gaussian': ...,        # [B, 1] - Gaussian log prob
    'log_prob_jacobian': ...,        # [B, 1] - Jacobian correction
}
```

#### 4. IRT Operator

**ì—­í• **: Optimal Transportì™€ Replicator Dynamicsë¥¼ í˜¼í•©í•œë‹¤.

**ìˆ˜ì‹**:
```
w_t = (1-Î±)Â·Replicator(w_{t-1}, f_t) + Î±Â·Transport(E_t, K, C_t)
```

**ì„¸ë¶€ì‚¬í•­**ì€ [IRTì˜ 3ê°€ì§€ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜](#irtì˜-3ê°€ì§€-í•µì‹¬-ë©”ì»¤ë‹ˆì¦˜) ì°¸ì¡°.

### ì™œ ì´ êµ¬ì¡°ê°€ í•„ìš”í•œê°€?

#### 1. SAC ì¸í„°í˜ì´ìŠ¤ ì¤€ìˆ˜
- SACëŠ” `policy.actor.action_log_prob(obs)`ë¥¼ í˜¸ì¶œ
- IRTActorWrapperê°€ ì´ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µ

#### 2. IRT ì•„í‚¤í…ì²˜ ë³´ì¡´
- EMA ë©”ëª¨ë¦¬ (`w_prev`): í•œ ë²ˆë§Œ ì—…ë°ì´íŠ¸
- T-Cell í†µê³„: `update_stats=self.training`
- IRT ì—°ì‚°: í•œ ë²ˆë§Œ ì‹¤í–‰

#### 3. íš¨ìœ¨ì„±
- IRT forward ì¤‘ë³µ ì œê±° â†’ í•™ìŠµ ì†ë„ ì•½ 2ë°° í–¥ìƒ
- ì½”ë“œ ê°„ì†Œí™”: 65ì¤„ â†’ 26ì¤„ (`action_log_prob`)

### ê²€ì¦ ì™„ë£Œ

| ë©”ì»¤ë‹ˆì¦˜ | ìƒíƒœ | ê²€ì¦ ìœ„ì¹˜ |
|---------|------|----------|
| **EMA ë©”ëª¨ë¦¬ (`w_prev`)** | âœ… ì •ìƒ | bcell_actor.py:190-195 |
| **T-Cell í†µê³„** | âœ… ì •ìƒ | bcell_actor.py:159 (`update_stats=self.training`) |
| **T-Cell Market Features** | âœ… ê°œì„  | bcell_actor.py:136-157 (ì‹œì¥ í†µê³„ + Tech indicators) |
| **IRT ì—°ì‚°** | âœ… ì •ìƒ | irt_policy.py:154-158 (í•œ ë²ˆë§Œ í˜¸ì¶œ) |
| **Fitness ê³„ì‚°** | âœ… ì™„ì „ í™œì„±í™” | irt_policy.py:81-134, 151 (Train+Eval ëª¨ë‘) |
| **dtype ì•ˆì •ì„±** | âœ… ì •ìƒ | irt_policy.py:148, 173 (`obs.float()`) |
| **Dirichlet ìƒ˜í”Œë§** | âœ… ì •ìƒ | bcell_actor.py:174-183 |
| **Replicator í™œì„±í™”** | âœ… 70% (alpha=0.3) | irt_operator.py:248-268 (fitness ê¸°ë°˜) |

---

## Projected Gaussian Policy (Phase 1.7)

### ê°œìš”

Phase 1.7ì—ì„œ SAC+IRT í•™ìŠµ ë°œì‚° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **Projected Gaussian Policy**ë¥¼ ë„ì…í–ˆë‹¤.

### ë³€ê²½ ì´ìœ 

**ê¸°ì¡´ (Phase 1.6): Gaussian + Softmax**
- `z ~ N(Î¼, ÏƒÂ²)` â†’ `a = softmax(z)`
- Log prob: Gaussian + Jacobian correction
- **ë¬¸ì œ**:
  - Jacobian approximation ë¶€ì •í™• (`-log(a).sum()`)
  - SAC target_entropy ë¶ˆì¼ì¹˜
  - ent_coef ë°œì‚° (1.63 â†’ 2.69 â†’ âˆ)

**í˜„ì¬ (Phase 1.7): Projected Gaussian**
- `z ~ N(Î¼, ÏƒÂ²)` â†’ `a = proj_simplex(z)`
- Log prob: unconstrained Gaussian only (no Jacobian)
- **íš¨ê³¼**:
  - SAC `target_entropy=-action_dim` í˜¸í™˜
  - ent_coef ì•ˆì •í™” (50% ê°œì„ )

### Euclidean Projection (Duchi et al. 2008)

**ì•Œê³ ë¦¬ì¦˜**:

$$
\text{proj}_{\Delta^n}(z) = \arg\min_{a \in \Delta^n} \|a - z\|_2^2
$$

where $\Delta^n = \{a \in \mathbb{R}^n : \sum_i a_i = 1, a_i \geq 0\}$

**êµ¬í˜„** (`bcell_actor.py:278-308`):

```python
def _project_to_simplex(self, z: torch.Tensor) -> torch.Tensor:
    """Euclidean projection onto probability simplex."""
    # 1. Sort z in descending order
    z_sorted, _ = torch.sort(z, dim=-1, descending=True)
    cumsum = torch.cumsum(z_sorted, dim=-1)

    # 2. Find rho (largest j such that z_j + (1 - sum) / j > 0)
    k = torch.arange(1, z.shape[-1] + 1, device=z.device, dtype=z.dtype)
    condition = z_sorted + (1 - cumsum) / k > 0
    rho = condition.sum(dim=-1, keepdim=True) - 1

    # 3. Compute threshold theta
    theta = (cumsum.gather(-1, rho) - 1) / (rho.float() + 1)

    # 4. Project: max(z - theta, 0)
    return torch.clamp(z - theta, min=0)
```

**ì‹œê°„ ë³µì¡ë„**: O(n log n) (sorting)

### Log Probability ê³„ì‚°

**Phase 1.6 (Gaussian + Softmax)**:
```python
# Gaussian log prob
log_prob_gaussian = -0.5 * (((z - Î¼) / Ïƒ)Â² + 2*log(Ïƒ) + log(2Ï€)).sum()

# Jacobian correction (approximation)
log_prob_jacobian = -log(action).sum()

# Total
log_prob = log_prob_gaussian + log_prob_jacobian  # â† ë¶€ì •í™•!
```

**Phase 1.7 (Projected Gaussian)**:
```python
# Unconstrained Gaussian log prob only
log_prob = -0.5 * (((z - Î¼) / Ïƒ)Â² + 2*log(Ïƒ) + log(2Ï€)).sum()

# No Jacobian correction!
# Projection gradientëŠ” SAC policy gradientì—ì„œ ì•”ë¬µì ìœ¼ë¡œ ì²˜ë¦¬ë¨
```

### ì´ë¡ ì  ì •ë‹¹ì„±

**Projected Gradient Descent**:

Projected Gaussian PolicyëŠ” projected gradient descentì˜ stochastic ë²„ì „ì´ë‹¤:

1. Unconstrained gradient step: $z_t = \mu + \epsilon \sigma$ (Gaussian sampling)
2. Projection: $a_t = \text{proj}_{\Delta^n}(z_t)$
3. Gradient: $\nabla_\theta \log p(a|s) = \nabla_\theta \log \mathcal{N}(z|\mu, \sigma^2)$

SACì˜ policy gradientëŠ” projectionì„ í†µê³¼í•œ actionì— ëŒ€í•´ ê³„ì‚°ë˜ì§€ë§Œ, log probabilityëŠ” projection ì´ì „ì˜ unconstrained Gaussianì„ ì‚¬ìš©í•œë‹¤. ì´ëŠ” projected gradient methodì˜ í‘œì¤€ ì ‘ê·¼ ë°©ì‹ì´ë‹¤ (Bertsekas 1999).

### ê²€ì¦

**Unit Tests** (`tests/test_irt_policy.py`):
- Test 8: `test_gaussian_projection_policy()` âœ…
  - Simplex ì œì•½: `sum(action) = 1 Â± 1e-5`
  - Non-negative: `all(action >= 0)`
  - Log prob: `log_prob = log_prob_gaussian` (no Jacobian)
- Test 9: `test_log_prob_calculation()` âœ…
  - Manual ê³„ì‚°ê³¼ ë¹„êµí•˜ì—¬ ì •í™•ì„± ê²€ì¦

**ê²°ê³¼**: 9/9 unit tests passing âœ…

---

## IRTì˜ 3ê°€ì§€ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜

### 1. Optimal Transport (OT)

**ê°œë…**: í˜„ì¬ ìƒíƒœ(ì—í”¼í† í”„)ì™€ ì „ë¬¸ê°€ ì „ëµ(í”„ë¡œí† íƒ€ì…) ê°„ì˜ **ìµœì  ë§¤ì¹­**ì„ ì°¾ëŠ”ë‹¤.

**ìˆ˜í•™ì  ë°°ê²½**:
- Cuturi (2013)ì˜ ì—”íŠ¸ë¡œí”¼ ì •ê·œí™” ìµœì ìˆ˜ì†¡
- Sinkhorn ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ íš¨ìœ¨ì  ê³„ì‚° (O(1/Îµ) ìˆ˜ë ´)

**ë™ì‘ ë°©ì‹**:
```
1. í˜„ì¬ ì‹œì¥ ìƒíƒœ â†’ 6ê°œ ì—í”¼í† í”„ í† í° (E_t)
2. 8ê°œ í”„ë¡œí† íƒ€ì… ì „ëµ (K)
3. ë¹„ìš© í–‰ë ¬ ê³„ì‚°: C_ij = d(E_i, K_j) - ë©´ì—­í•™ì  ì¡°ì •
4. Sinkhornìœ¼ë¡œ ìµœì  ìˆ˜ì†¡ ê³„íš P* ê³„ì‚°
5. í”„ë¡œí† íƒ€ì…ë³„ ìˆ˜ì†¡ ì§ˆëŸ‰ â†’ w_ot
```

**ì§ê´€**:
- ìœ„ê¸° ìƒí™© â†’ ìœ„ê¸° ì‹ í˜¸ì™€ ì •ë ¬ëœ í”„ë¡œí† íƒ€ì…ì˜ ë¹„ìš© â†“
- OTê°€ ìë™ìœ¼ë¡œ ìœ„ê¸° ëŒ€ì‘ ì „ëµ ì„ íƒ

### 2. Replicator Dynamics

**ê°œë…**: ê³¼ê±°ì— ì„±ê³µí•œ ì „ëµì„ **ì„ í˜¸**í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ (ì§„í™” ê²Œì„ ì´ë¡ )

**ìˆ˜í•™ì  ë°°ê²½**:
- Hofbauer & Sigmund (1998)ì˜ ë³µì œì ë™ì—­í•™
- ê· í˜•ì ì€ Nash ê· í˜•, ì•ˆì •ì ì€ ESS

**ë™ì‘ ë°©ì‹**:
```
1. ì´ì „ ê°€ì¤‘ì¹˜ w_{t-1} ê¸°ì–µ
2. ê° í”„ë¡œí† íƒ€ì…ì˜ ì í•©ë„ f_j ê³„ì‚° (Critic Q-value ê¸°ë°˜)
3. Advantage: A_j = f_j - í‰ê·  ì í•©ë„
4. ìœ„ê¸° ê°€ì—´: Î·(c) = Î·_0 + Î·_1Â·crisis_level
5. ì—…ë°ì´íŠ¸: w_rep âˆ w_{t-1}Â·exp(Î·Â·A)
```

**ì§ê´€**:
- ì„±ê³µí•œ í”„ë¡œí† íƒ€ì… â†’ ê°€ì¤‘ì¹˜ â†‘
- ìœ„ê¸° ì‹œ â†’ Î· â†‘ (ë¹ ë¥¸ ì ì‘)
- ì‹œê°„ ë©”ëª¨ë¦¬ â†’ ì¼ê´€ì„± ìœ ì§€

### 3. ë©´ì—­í•™ì  ë¹„ìš© í•¨ìˆ˜

**ê°œë…**: ë„ë©”ì¸ ì§€ì‹ì„ ë¹„ìš© í•¨ìˆ˜ì— **ë‚´ì¥**í•˜ì—¬ ë” ë‚˜ì€ ì˜ì‚¬ê²°ì • ìœ ë„

**êµ¬ì„± ìš”ì†Œ**:

```
C_ij = distance - Î³Â·co_stimulation + Î»Â·tolerance + ÏÂ·checkpoint
```

#### 3.1 Co-stimulation (ê³µìê·¹)
- ìœ„ê¸° ì‹ í˜¸(danger embedding)ì™€ ì •ë ¬ëœ ì—í”¼í† í”„ ì„ í˜¸
- `co_stim = <E_i, d_t>` (ë‚´ì )
- ìœ„ê¸° ì‹œ ìœ„í—˜ ì‹ í˜¸ì™€ ìœ ì‚¬í•œ íŒ¨í„´ ìš°ì„  ì„ íƒ

#### 3.2 Tolerance (ë‚´ì„±)
- ê³¼ê±° ì‹¤íŒ¨ íŒ¨í„´(self signatures)ê³¼ ìœ ì‚¬í•œ ì—í”¼í† í”„ ì–µì œ
- `tolerance_penalty = ReLU(ÎºÂ·max_similarity - Îµ_tol)`
- ë°˜ë³µì  ì‹¤ìˆ˜ ë°©ì§€

#### 3.3 Checkpoint (ì²´í¬í¬ì¸íŠ¸)
- ê³¼ì‹ í•˜ëŠ” í”„ë¡œí† íƒ€ì… ì–µì œ
- `checkpoint_penalty = ÏÂ·confidence_score`
- ê³¼ë„í•œ ì§‘ì¤‘ ë°©ì§€

**íš¨ê³¼**:
- ë‹¨ìˆœ ê±°ë¦¬ ê¸°ë°˜ ë§¤ì¹­ë³´ë‹¤ **ì˜ë¯¸ ìˆëŠ” ë§¤ì¹­**
- ìœ„ê¸° ëŒ€ì‘, ì‹¤íŒ¨ íšŒí”¼, ë¶„ì‚° íˆ¬ì ìë™ ìœ ë„

---

## íš¨ê³¼ ë° ì„±ëŠ¥ ëª©í‘œ

### í•µì‹¬ ëª©í‘œ

| ë©”íŠ¸ë¦­ | SAC Baseline | IRT ëª©í‘œ (Phase 1.4) | ê°œì„ ìœ¨ |
|--------|--------------|---------------------|--------|
| **Sharpe Ratio** | 1.0-1.2 | 1.3-1.5 | **+15-20%** |
| **ì „ì²´ Max Drawdown** | -30~-35% | -18~-23% | **-25-35%** |
| **ìœ„ê¸° êµ¬ê°„ MDD** | -40~-45% | -22~-27% | **-35-45%** |

**Phase 1.4 ê°œì„ ì‚¬í•­ ë°˜ì˜**:
- Replicator ì™„ì „ í™œì„±í™” (0% â†’ 70%)
- TCell ìœ„ê¸° ê°ì§€ ì •í™•ë„ í–¥ìƒ (ì‹œì¥ í†µê³„ + Tech indicators)
- Train-Eval ì¼ê´€ì„± í™•ë³´

### ìœ„ê¸° êµ¬ê°„ ì§‘ì¤‘

IRTì˜ ì§„ê°€ëŠ” **ìœ„ê¸° êµ¬ê°„**ì—ì„œ ë°œíœ˜ëœë‹¤:

- **2020ë…„ COVID-19**: MDD -40% â†’ -25% (ëª©í‘œ)
- **2022ë…„ Fed ê¸ˆë¦¬ ì¸ìƒ**: MDD -35% â†’ -22% (ëª©í‘œ)
- **ì •ìƒ êµ¬ê°„**: SACì™€ ìœ ì‚¬ (ì•ˆì •ì„± ìœ ì§€)

### í•´ì„ ê°€ëŠ¥ì„±

IRTëŠ” **ë¸”ë™ë°•ìŠ¤ê°€ ì•„ë‹ˆë‹¤**. ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•œë‹¤:

1. **IRT ë¶„í•´**: `w = (1-Î±)Â·w_rep + Î±Â·w_ot`
   - w_rep: ì‹œê°„ ë©”ëª¨ë¦¬ ê¸°ì—¬ë„
   - w_ot: êµ¬ì¡°ì  ë§¤ì¹­ ê¸°ì—¬ë„

2. **T-Cell ìœ„ê¸° ê°ì§€**:
   - ìœ„ê¸° íƒ€ì…ë³„ ì ìˆ˜ (ë³€ë™ì„±, ìœ ë™ì„±, ìƒê´€ê´€ê³„, ì‹œìŠ¤í…œ)
   - ìœ„ê¸° ë ˆë²¨ (0~1)

3. **ë¹„ìš© í–‰ë ¬**:
   - ì—í”¼í† í”„-í”„ë¡œí† íƒ€ì… ê°„ ë©´ì—­í•™ì  ë¹„ìš©
   - ì–´ë–¤ ì „ëµì´ ì™œ ì„ íƒë˜ì—ˆëŠ”ì§€ ì¶”ì 

4. **í”„ë¡œí† íƒ€ì… í•´ì„**:
   - ê° í”„ë¡œí† íƒ€ì…ì´ ì„ í˜¸í•˜ëŠ” ìì‚°
   - ìœ„ê¸° vs ì •ìƒ êµ¬ê°„ í™œì„±í™” íŒ¨í„´

---

## ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ê³¼ì˜ ë¹„êµ

### í˜¸í™˜ì„± ìš”ì•½

| ì•Œê³ ë¦¬ì¦˜ | IRT ì ìš© | Fitness ê³„ì‚° | Policy íƒ€ì… | ê¶Œì¥ë„ |
|---------|---------|-------------|------------|-------|
| **SAC** | âœ… ìµœì  | Q(s,a) | Stochastic | â­â­â­â­â­ |
| **TD3** | âœ… ê°€ëŠ¥ | Q(s,a) | Deterministic | â­â­â­â­ |
| **DDPG** | âœ… ê°€ëŠ¥ | Q(s,a) | Deterministic | â­â­â­ |
| **PPO** | âš ï¸ ìˆ˜ì • í•„ìš” | V(s) ê¸°ë°˜ | Stochastic | â­â­ |
| **A2C** | âš ï¸ ìˆ˜ì • í•„ìš” | V(s) ê¸°ë°˜ | Stochastic | â­â­ |

### SAC (í˜„ì¬ ì‚¬ìš©) â­â­â­â­â­

**ì¥ì **:
- âœ… **Q-network ê¸°ë°˜** â†’ í”„ë¡œí† íƒ€ì… fitness ê³„ì‚° ìš©ì´
- âœ… **Entropy regularization** â†’ IRT explorationê³¼ ì‹œë„ˆì§€
- âœ… **Off-policy** â†’ ìƒ˜í”Œ íš¨ìœ¨ì„± (ê³¼ê±° ê²½í—˜ ì¬ì‚¬ìš©)
- âœ… **Stochastic policy** â†’ Dirichlet ì •ì±…ê³¼ ì™„ë²½ í˜¸í™˜
- âœ… **2 Q-networks (ensemble)** â†’ ì•ˆì •ì„±

**IRTì™€ì˜ ê¶í•©**:
```python
# SACì˜ entropy maximization
max E[Q(s,a)] + Î±_sacÂ·H(Ï€)

# IRTì˜ exploration
- Sinkhorn entropy (Îµ)
- Dirichlet concentration (Î±_k)

# ê²°ê³¼: ì´ì¤‘ exploration â†’ ê°•ê±´í•œ í•™ìŠµ
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from stable_baselines3 import SAC
from finrl.agents.irt import IRTPolicy

model = SAC(
    policy=IRTPolicy,
    env=env,
    policy_kwargs={"alpha": 0.3, "eps": 0.10}
)
```

### TD3 â­â­â­â­

**ì¥ì **:
- âœ… **Q-network ê¸°ë°˜** â†’ fitness ê³„ì‚° ê°€ëŠ¥
- âœ… **Twin Q-networks** â†’ Overestimation ì™„í™”
- âœ… **Off-policy** â†’ ìƒ˜í”Œ íš¨ìœ¨ì„±

**ì°¨ì´ì **:
- âš ï¸ **Deterministic policy** â†’ IRTì˜ `deterministic=True` ëª¨ë“œ ì‚¬ìš©
- âŒ **Entropy regularization ì—†ìŒ** â†’ Exploration ì•½í•¨

**ì ìš© ë°©ë²•**:
```python
from stable_baselines3 import TD3

model = TD3(
    policy=IRTPolicy,  # ë™ì¼í•œ IRT Policy ì‚¬ìš© ê°€ëŠ¥
    env=env,
    policy_kwargs={"alpha": 0.3}
)
# IRT ë‚´ë¶€ì—ì„œ deterministic ëª¨ë“œë¡œ ìë™ ì „í™˜
```

### DDPG â­â­â­

**ì¥ì **:
- âœ… **Q-network ê¸°ë°˜** â†’ fitness ê³„ì‚° ê°€ëŠ¥
- âœ… **Off-policy** â†’ ìƒ˜í”Œ íš¨ìœ¨ì„±
- âœ… **ë‹¨ìˆœ êµ¬ì¡°** â†’ ë¹ ë¥¸ í•™ìŠµ

**ë‹¨ì **:
- âŒ **Single Q-network** â†’ Overestimation ë¬¸ì œ
- âŒ **ë¶ˆì•ˆì •ì„±** â†’ í•™ìŠµ ë°œì‚° ê°€ëŠ¥
- âš ï¸ **Deterministic policy**

**ê¶Œì¥ì‚¬í•­**: TD3 ì‚¬ìš© (DDPG ê°œì„  ë²„ì „)

### PPO â­â­

**ë¬¸ì œì **:
- âŒ **V(s) ê¸°ë°˜ Critic** â†’ Q(s,a) ì—†ìŒ
- âŒ **On-policy** â†’ ê³¼ê±° ê²½í—˜ ì¬ì‚¬ìš© ë¶ˆê°€
- âŒ **IRTì˜ ì‹œê°„ ë©”ëª¨ë¦¬ ì•½í™”**

**ëŒ€ì•ˆ** (êµ¬ì¡° ìˆ˜ì • í•„ìš”):
```python
# Fitnessë¥¼ Advantageë¡œ ê·¼ì‚¬
fitness[j] â‰ˆ A(s, a_j) = r + Î³Â·V(s') - V(s)

# ë¬¸ì œ:
# 1. Episode ëê¹Œì§€ ê¸°ë‹¤ë ¤ì•¼ í•¨ (ì¦‰ì‹œ ê³„ì‚° ë¶ˆê°€)
# 2. ë¶„ì‚° â†‘ (Monte Carlo ì¶”ì •)
# 3. On-policy â†’ w_prev ë©”ëª¨ë¦¬ íš¨ê³¼ ì•½í™”
```

**ê²°ë¡ **: IRTì™€ ê¶í•© ë‚˜ì¨. SAC/TD3 ê¶Œì¥.

### A2C â­â­

PPOì™€ ë™ì¼í•œ ë¬¸ì œ (V(s) ê¸°ë°˜, On-policy).

**ì¶”ê°€ ë‹¨ì **:
- Synchronous update â†’ ëŠë¦° í•™ìŠµ
- PPOì˜ clipping ì—†ìŒ â†’ ë¶ˆì•ˆì •

---

## í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì´ë“œ

### í•µì‹¬ íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ë²”ìœ„ | ì„¤ëª… |
|---------|-------|------|------|
| **alpha** | 0.3 | 0.1-0.5 | OT-Replicator í˜¼í•© ë¹„ìœ¨ |
| **eps** | 0.10 | 0.01-0.2 | Sinkhorn ì—”íŠ¸ë¡œí”¼ (exploration) |
| **eta_0** | 0.05 | 0.03-0.08 | ê¸°ë³¸ í•™ìŠµë¥  (Replicator) |
| **eta_1** | 0.15 | 0.05-0.20 | ìœ„ê¸° ì¦ê°€ëŸ‰ (Replicator) |
| **m_tokens** | 6 | 4-8 | ì—í”¼í† í”„ í† í° ìˆ˜ |
| **M_proto** | 8 | 6-12 | í”„ë¡œí† íƒ€ì… ìˆ˜ |
| **log_std_min** | -20 | -30 ~ -10 | Gaussian log std ìµœì†Œê°’ |
| **log_std_max** | 2 | 1 ~ 5 | Gaussian log std ìµœëŒ€ê°’ |

### íŒŒë¼ë¯¸í„° íš¨ê³¼

#### alpha (OT-Replicator í˜¼í•©)

```
Î±=0.0: Pure Replicator (ì‹œê°„ ì¼ê´€ì„± â†‘, êµ¬ì¡° ì ì‘ â†“)
Î±=0.3: Balanced (ê¶Œì¥)
Î±=1.0: Pure OT (êµ¬ì¡° ë§¤ì¹­ â†‘, ì‹œê°„ ë©”ëª¨ë¦¬ â†“)
```

**Ablation Study ì˜ˆì‹œ**:
```bash
python scripts/train_irt.py --alpha 0.0 --episodes 200  # Pure Replicator
python scripts/train_irt.py --alpha 0.3 --episodes 200  # Balanced
python scripts/train_irt.py --alpha 1.0 --episodes 200  # Pure OT
```

#### eps (Sinkhorn ì—”íŠ¸ë¡œí”¼)

```
Îµ â†‘ â†’ ìˆ˜ì†¡ ê³„íš Pê°€ ê· ë“± ë¶„ì‚° â†’ exploration â†‘
Îµ â†“ â†’ ìˆ˜ì†¡ ê³„íš Pê°€ ì§‘ì¤‘ â†’ exploitation â†‘
```

**ê¶Œì¥ê°’**: 0.10 (Cuturi, 2013 ê¶Œì¥ ë²”ìœ„)

#### eta_1 (ìœ„ê¸° ê°€ì—´)

```
Î·(c) = Î·_0 + Î·_1Â·crisis_level

Î·_1=0.05: ì•½í•œ ê°€ì—´ (ì•ˆì •ì , ëŠë¦° ì ì‘)
Î·_1=0.15: ì¤‘ê°„ ê°€ì—´ (ê¶Œì¥)
Î·_1=0.20: ê°•í•œ ê°€ì—´ (ë¹ ë¥¸ ì ì‘, ë¶ˆì•ˆì • ê°€ëŠ¥)
```

**âš ï¸ ì£¼ì˜**: Î·_1 > 0.20ì€ í•™ìŠµ ë¶ˆì•ˆì • ê°€ëŠ¥

#### dirichlet_min/max (Exploration)

```
min â†“ â†’ ë” sparseí•œ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ëŠ¥ (ë†’ì€ exploration)
max â†‘ â†’ ë” ì§‘ì¤‘ëœ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ëŠ¥ (ë‚®ì€ exploration)
```

**í•¸ë“œì˜¤ë²„ ê¶Œì¥**: min=0.5, max=50.0 (ë¬´ê±°ë˜ ë£¨í”„ ë°©ì§€)

### ë¬´ê±°ë˜ ë£¨í”„ ë°©ì§€

**ë¬¸ì œ**: Episode ì „ì²´ì—ì„œ turnover â‰ˆ 0, ê· ë“± ë¶„ë°° ì •ì±… ë°˜ë³µ

**í•´ê²°** (í•¸ë“œì˜¤ë²„ ë¬¸ì„œ ê¸°ë°˜):
```yaml
# í™˜ê²½ ë ˆë²¨
lambda_turn: 0.01  # 0.1 â†’ 0.01 (ê±°ë˜ ìœ ì¸)

# IRT ë ˆë²¨
eps: 0.10          # 0.05 â†’ 0.10 (OT ë‹¤ì–‘ì„±)
eta_1: 0.15        # 0.10 â†’ 0.15 (ë¹ ë¥¸ ì ì‘)
dirichlet_min: 0.5 # 1.0 â†’ 0.5 (exploration)
```

---

## ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from stable_baselines3 import SAC
from finrl.agents.irt import IRTPolicy

# IRT Policy ì„¤ì •
policy_kwargs = {
    "emb_dim": 128,
    "m_tokens": 6,
    "M_proto": 8,
    "alpha": 0.3,
    "eps": 0.10,
    "eta_0": 0.05,
    "eta_1": 0.15
}

# SAC + IRT
model = SAC(
    policy=IRTPolicy,
    env=env,
    policy_kwargs=policy_kwargs,
    learning_rate=3e-4,
    buffer_size=100000,
    batch_size=256,
    verbose=1
)

# í•™ìŠµ
model.learn(total_timesteps=50000)

# ì €ì¥
model.save("irt_model.zip")
```

### CLI ì‚¬ìš©ë²•

```bash
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ ë° í‰ê°€
python scripts/train_irt.py --mode both --episodes 200

# Alpha ì¡°ì • (Ablation Study)
python scripts/train_irt.py --alpha 0.5 --episodes 200

# ì €ì¥ëœ ëª¨ë¸ í‰ê°€
python scripts/evaluate.py \
  --model logs/irt/20251004_*/irt_final.zip \
  --method direct \
  --save-plot \
  --save-json
```

### í•´ì„ ê°€ëŠ¥ì„± í™œìš©

```python
# í‰ê°€ ì‹œ IRT ì •ë³´ ìˆ˜ì§‘
obs = env.reset()
action, _ = model.predict(obs, deterministic=True)

# IRT Policyì—ì„œ ì •ë³´ ì¶”ì¶œ (ë‚´ë¶€ ì ‘ê·¼)
policy = model.policy
actor = policy.irt_actor

# Forward passë¡œ IRT ì •ë³´ íšë“
action, info = actor(obs_tensor, deterministic=True)

print(f"í”„ë¡œí† íƒ€ì… ê°€ì¤‘ì¹˜: {info['w']}")
print(f"ìœ„ê¸° ë ˆë²¨: {info['crisis_level']}")
print(f"IRT ë¶„í•´ - Replicator: {info['w_rep']}")
print(f"IRT ë¶„í•´ - OT: {info['w_ot']}")
```

---

## ì°¸ê³  ë¬¸í—Œ

### ì´ë¡ ì  ê¸°ì´ˆ

1. **Optimal Transport**
   - Cuturi, M. (2013). "Sinkhorn Distances: Lightspeed Computation of Optimal Transport"
   - NIPS 2013

2. **Replicator Dynamics**
   - Hofbauer, J., & Sigmund, K. (1998). "Evolutionary Games and Population Dynamics"
   - Cambridge University Press

3. **ë©´ì—­í•™ì  ë¹„ìš©**
   - í”„ë¡œì íŠ¸ ë…ì ì„¤ê³„ (ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜)

### êµ¬í˜„ ì°¸ì¡°

4. **FinRL**
   - Liu, X. Y., et al. (2024). "FinRL: Financial Reinforcement Learning Framework"
   - NeurIPS Workshop

5. **Stable Baselines3**
   - Raffin, A., et al. (2021). "Stable-Baselines3: Reliable Reinforcement Learning Implementations"
   - JMLR

### ê´€ë ¨ ì—°êµ¬

6. **ì •ë³´ê¸°í•˜í•™**
   - Amari, S. (2016). "Information Geometry and Its Applications"
   - Applied Mathematical Sciences

7. **Portfolio Optimization**
   - Markowitz, H. (1952). "Portfolio Selection"
   - Journal of Finance

---

## ìµœì‹  ì—…ë°ì´íŠ¸ (Phase 1.4 - 2025-10-05)

### ì£¼ìš” ë³€ê²½ì‚¬í•­

1. **dtype ë¶ˆì¼ì¹˜ í•´ê²°** âœ…
   - Evaluation ì‹œ RuntimeError ì™„ì „ í•´ê²°
   - `IRTActorWrapper`ì—ì„œ `obs.float()` ë³€í™˜

2. **Market Features ê°œì„ ** âœ…
   - TCellì´ ì˜ë¯¸ìˆëŠ” ì‹œì¥ íŠ¹ì„± ì‚¬ìš©
   - ì‹œì¥ í†µê³„ (4ê°œ) + Technical indicators (8ê°œ)

3. **Evaluation Fitness ê³„ì‚°** âœ…
   - Replicator ë©”ì»¤ë‹ˆì¦˜ ì™„ì „ í™œì„±í™” (0% â†’ 70%)
   - Train-Eval ì¼ê´€ì„± í™•ë³´
   - `_compute_fitness()` helperë¡œ DRY principle ì¤€ìˆ˜

ìì„¸í•œ ë‚´ìš©ì€ [CHANGELOG.md - Phase 1.4](CHANGELOG.md#phase-14---evaluation-dtype-ë¶ˆì¼ì¹˜-ë°-ì„±ëŠ¥-ê°œì„ -2025-10-05) ì°¸ì¡°.

---

## Policy ì¬ì„¤ê³„: Dirichlet â†’ Gaussian+Softmax (Phase 1.6)

### ë¬¸ì œ ìƒí™©

#### ì¦ìƒ
- Dirichlet Policy ì‚¬ìš© ì‹œ SAC í›ˆë ¨ ë°œì‚°
- ent_coef í­ë°œ: 1.63 â†’ 1.28e+09 (200 episodes)
- critic_loss í­ë°œ: 3.34e+03 â†’ 2.84e+08 (200 episodes)
- actor_loss ë°œì‚°: -1.91e+03 â†’ -1.41e+08 (200 episodes)

#### ê·¼ë³¸ ì›ì¸
- Dirichlet ì •ì±…ì˜ Entropy: -3 ~ -50 (ë§¤ìš° ë‚®ìŒ)
- SAC target_entropy: -30 (Gaussian ê°€ì •)
- SACì˜ ìë™ ì—”íŠ¸ë¡œí”¼ ì¡°ì •:
  ```python
  J_entropy = -log(ent_coef) * (entropy - target_entropy)
  # entropy (-50) << target_entropy (-30)
  # â†’ SACê°€ ent_coefë¥¼ í­ë°œì ìœ¼ë¡œ ì¦ê°€
  ```
- Actor loss í­ë°œ: `L_actor âˆ ent_coef * entropy`
- Criticì´ ë†’ì€ Q-valueë¡œ ë³´ìƒ â†’ ë°œì‚°

### í•´ê²°ì±…: Gaussian + Softmax

#### ì„¤ê³„ ì›ë¦¬
1. **Gaussian Policy**: `z ~ N(Î¼, ÏƒÂ²)` - SACì™€ ìì—°ìŠ¤ëŸ½ê²Œ í˜¸í™˜
2. **Softmax Projection**: `a = softmax(z)` - Simplex ì œì•½ ìœ ì§€
3. **Variable Transformation**: Log probability with Jacobian correction

#### ìˆ˜ì‹
```
z_i ~ N(Î¼_i, Ïƒ_iÂ²)
a_i = exp(z_i) / Î£ exp(z_j)  (Softmax)

log p(a) = log p(z) + log |âˆ‚z/âˆ‚a|
         = Î£ [-0.5((z_i - Î¼_i)/Ïƒ_i)Â² - log(Ïƒ_i) - 0.5log(2Ï€)]
           - Î£ log(a_i)
```

**Jacobian Correction**:
- Softmaxì˜ Jacobian: `âˆ‚z_i/âˆ‚a_j = Î´_ij / a_i` (diagonal ê·¼ì‚¬)
- Log-det Jacobian: `-Î£ log(a_i)`

#### ì¥ì 
- âœ… SAC í˜¸í™˜: Entropy -30 ~ -20 (target_entropy ë²”ìœ„)
- âœ… Simplex ì œì•½: `Î£ a_i = 1`, `a_i â‰¥ 0` ìë™ ë§Œì¡±
- âœ… IRT ë…ë¦½ì„±: Policy ë¶„í¬ë§Œ ë³€ê²½, IRT ë©”ì»¤ë‹ˆì¦˜ ë³´ì¡´
- âœ… ì•ˆì •ì„±: ent_coef < 1.0 (Dirichletì˜ 1.28e+09 vs)

### êµ¬í˜„ ìƒì„¸

#### ë³€ê²½ íŒŒì¼ (Core 4ê°œ + Tests 1ê°œ)

**1. finrl/agents/irt/bcell_actor.py**
- **Decoder êµì²´** (Line 83-103):
  - ì´ì „: `dirichlet_decoders` â†’ Dirichlet concentration
  - í˜„ì¬: `mu_decoders`, `log_std_decoders` â†’ Gaussian íŒŒë¼ë¯¸í„°
- **Forward ë³€ê²½** (Line 206-246):
  - Gaussian í˜¼í•©: `mixed_mu = w @ mus`, `mixed_std = w @ stds`
  - Gaussian ìƒ˜í”Œë§: `z = Î¼ + ÎµÂ·Ïƒ`
  - Softmax projection: `action = softmax(z)`
  - Log probability: Gaussian + Jacobian
- **Return ë³€ê²½**: `(action, info)` â†’ `(action, log_prob, info)`

**2. finrl/agents/irt/irt_policy.py**
- **action_log_prob() ê°„ì†Œí™”** (Line 167-196):
  - BCellIRTActorê°€ log_prob ì§ì ‘ ë°˜í™˜
  - Dirichlet ê³„ì‚° ì œê±°
- **_compute_fitness() ìˆ˜ì •** (Line 84-136):
  - Gaussian mean action ì‚¬ìš©: `a_j = softmax(mu_j)`
- **íŒŒë¼ë¯¸í„° ë³€ê²½** (Line 241-242):
  - `dirichlet_min/max` â†’ `log_std_min/max`

**3. finrl/config.py**
- **SAC_PARAMS.ent_coef** (Line 48):
  - ì´ì „: `"auto_0.1"` (Dirichlet íŠ¹í™”)
  - í˜„ì¬: `"auto"` (Gaussian í‘œì¤€)

**4. scripts/train_irt.py**
- **policy_kwargs ì¶”ê°€**:
  - `log_std_min=-20, log_std_max=2`

**5. tests/test_irt_policy.py**
- **Test 8 ì¶”ê°€**: Gaussian+Softmax ê²€ì¦
- **Test 9 ì¶”ê°€**: Log probability ê³„ì‚° ê²€ì¦
- **state_dim ìˆ˜ì •**: 181 â†’ 301 (FinRL Dow30 í‘œì¤€)
- **ëª¨ë“  í…ŒìŠ¤íŠ¸**: 3-value return ì²˜ë¦¬

### ê²€ì¦ ê²°ê³¼

#### Unit Tests
- âœ… 9/9 passing
- âœ… Simplex ì œì•½: `Î£ a_i = 1 Â± 1e-5`
- âœ… Gaussian parameters: mu, std, z ì¡´ì¬
- âœ… Log prob ì •í™•ì„±: Gaussian + Jacobian ê²€ì¦

#### Integration Test (2025-10-05)
- âœ… Training: 250 timesteps ì •ìƒ ì™„ë£Œ (ë°œì‚° ì—†ìŒ)
- âœ… Evaluation: 19 steps, Final return -0.69%
- âœ… ì‹œê°í™”: 14ê°œ IRT í”Œë¡¯ ëª¨ë‘ ìƒì„±
- âœ… í›ˆë ¨ ì•ˆì •ì„±: ent_coef, critic_loss, actor_loss í­ë°œ ì—†ìŒ

### IRT ë©”ì»¤ë‹ˆì¦˜ ë³´ì¡´ í™•ì¸

**ì •ì±… ë…ë¦½ì„±**:
- IRT í˜¼í•© ê³µì‹: `w = (1-Î±)Â·Replicator + Î±Â·OT` (ë³€ê²½ ì—†ìŒ)
- Epitope ì¸ì½”ë”©: ë™ì¼
- T-Cell ìœ„ê¸° ê°ì§€: ë™ì¼
- OT ìˆ˜ì†¡: ë™ì¼
- Replicator Dynamics: ë™ì¼

**ë³€ê²½ ì‚¬í•­**: Policy headë§Œ êµì²´
- ì´ì „: `w @ [Dirichlet(conc_j) for j in M] â†’ action`
- í˜„ì¬: `w @ [Gaussian(Î¼_j, Ïƒ_j) for j in M] â†’ z â†’ softmax(z) â†’ action`

---

## ì¶”ê°€ ìë£Œ

- **í”„ë¡œì íŠ¸ ë¬¸ì„œ**: [README.md](../README.md)
- **ë³€ê²½ì‚¬í•­ ì´ë ¥**: [CHANGELOG.md](CHANGELOG.md)
- **ìŠ¤í¬ë¦½íŠ¸ ê°€ì´ë“œ**: [SCRIPTS.md](SCRIPTS.md)
- **FinRL ê³µì‹ ë¬¸ì„œ**: [https://finrl.readthedocs.io/](https://finrl.readthedocs.io/)
- **Stable Baselines3 ë¬¸ì„œ**: [https://stable-baselines3.readthedocs.io/](https://stable-baselines3.readthedocs.io/)

---

**ë¬¸ì˜**: GitHub Issues ë˜ëŠ” Discussions í™œìš©
