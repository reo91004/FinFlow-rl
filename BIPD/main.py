import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
from sklearn.metrics.pairwise import cosine_similarity
import warnings
import os
import pickle
import matplotlib.pyplot as plt
from datetime import datetime
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from tqdm import tqdm

warnings.filterwarnings("ignore")

# ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
MODELS_DIR = os.path.join(BASE_DIR, "models")
RESULTS_DIR = os.path.join(BASE_DIR, "results")

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)
os.makedirs(RESULTS_DIR, exist_ok=True)


class ImmuneCell:
    """ë©´ì—­ ì„¸í¬ ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self, cell_id, activation_threshold=0.5):
        self.cell_id = cell_id
        self.activation_threshold = activation_threshold
        self.activation_level = 0.0
        self.memory_strength = 0.0


class TCell(ImmuneCell):
    """T-ì„¸í¬: ìœ„í—˜ íƒì§€ ë‹´ë‹¹"""

    def __init__(self, cell_id, sensitivity=0.1, random_state=None):
        super().__init__(cell_id)
        self.sensitivity = sensitivity
        self.detector = IsolationForest(contamination=sensitivity, random_state=random_state)
        self.is_trained = False

    def detect_anomaly(self, market_features):
        """ì‹œì¥ ì´ìƒ ìƒí™© íƒì§€"""
        if not self.is_trained:
            # ì •ìƒ ì‹œì¥ ìƒíƒœë¡œ í›ˆë ¨
            self.detector.fit(market_features)
            self.is_trained = True
            return 0.0

        # ì´ìƒ ì ìˆ˜ ê³„ì‚° (-1: ì´ìƒ, 1: ì •ìƒ)
        anomaly_scores = self.detector.decision_function(market_features)

        # í™œì„±í™” ìˆ˜ì¤€ ê³„ì‚° (0~1)
        self.activation_level = max(0, (1 - np.mean(anomaly_scores)) / 2)

        return self.activation_level


class StrategyNetwork(nn.Module):
    """B-ì„¸í¬ì˜ ì „ëµ ìƒì„± ì‹ ê²½ë§"""
    
    def __init__(self, input_size, n_assets, hidden_size=64):
        super(StrategyNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, n_assets)
        self.dropout = nn.Dropout(0.1)
        
    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        # Softmaxë¡œ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ ì •ê·œí™”
        return F.softmax(x, dim=-1)


class GenerativeBCell(ImmuneCell):
    """ìƒì„±í˜• B-ì„¸í¬: ì‹ ê²½ë§ ê¸°ë°˜ ë™ì  ì „ëµ ìƒì„±"""

    def __init__(self, cell_id, risk_type, input_size, n_assets, learning_rate=0.001):
        super().__init__(cell_id)
        self.risk_type = risk_type
        self.n_assets = n_assets
        
        # ì‹ ê²½ë§ ì´ˆê¸°í™”
        self.strategy_network = StrategyNetwork(input_size, n_assets)
        self.optimizer = optim.Adam(self.strategy_network.parameters(), lr=learning_rate)
        
        # ê°•í™”í•™ìŠµ íŒŒë¼ë¯¸í„°
        self.experience_buffer = []
        self.episode_buffer = []  # í˜„ì¬ ì—í”¼ì†Œë“œ ê²½í—˜
        self.antibody_strength = 0.1
        self.epsilon = 0.3  # íƒí—˜ í™•ë¥ 
        self.epsilon_decay = 0.995
        self.min_epsilon = 0.05
        
        # í•™ìŠµ ì„¤ì •
        self.batch_size = 32
        self.update_frequency = 10  # Në²ˆì˜ ê²½í—˜ë§ˆë‹¤ í•™ìŠµ
        self.experience_count = 0
        
        # íŠ¹í™” ê°€ì¤‘ì¹˜ (ê° B-ì„¸í¬ì˜ ì „ë¬¸ì„±)
        self.specialization_weights = self._initialize_specialization(risk_type, n_assets)
        
    def _initialize_specialization(self, risk_type, n_assets):
        """ìœ„í—˜ ìœ í˜•ë³„ ì´ˆê¸° íŠ¹í™” ì„¤ì •"""
        weights = torch.ones(n_assets) * 0.1
        
        if risk_type == "volatility":
            # ì•ˆì „ ìì‚° ì„ í˜¸ (JPM, JNJ, PG)
            safe_indices = [6, 7, 8] if n_assets >= 9 else [n_assets-1]
            for idx in safe_indices:
                if idx < n_assets:
                    weights[idx] = 0.3
        elif risk_type == "correlation":
            # ë¶„ì‚° íˆ¬ì ì„ í˜¸
            weights = torch.ones(n_assets) * (0.8 / n_assets)
        elif risk_type == "momentum":
            # ì¤‘ë¦½ì  ê°€ì¤‘ì¹˜
            weights = torch.ones(n_assets) * 0.5
        elif risk_type == "liquidity":
            # ëŒ€í˜•ì£¼ ì„ í˜¸ (AAPL, MSFT, AMZN, GOOGL)
            large_cap_indices = [0, 1, 2, 3] if n_assets >= 4 else list(range(n_assets))
            for idx in large_cap_indices:
                if idx < n_assets:
                    weights[idx] = 0.25
        
        return weights

    def produce_antibody(self, market_features, crisis_level, training=True):
        """ì‹ ê²½ë§ì„ í†µí•œ í•­ì²´(ì „ëµ) ìƒì„± (íƒí—˜/í™œìš© í¬í•¨)"""
        try:
            # ì…ë ¥ ì¤€ë¹„
            features_tensor = torch.FloatTensor(market_features)
            crisis_tensor = torch.FloatTensor([crisis_level])
            
            # íŠ¹í™” ì •ë³´ ì¶”ê°€
            specialization_tensor = self.specialization_weights
            
            # ëª¨ë“  ì •ë³´ë¥¼ ê²°í•©
            combined_input = torch.cat([features_tensor, crisis_tensor, specialization_tensor])
            
            # ì‹ ê²½ë§ì„ í†µí•œ ì „ëµ ìƒì„±
            with torch.no_grad():
                raw_strategy = self.strategy_network(combined_input.unsqueeze(0))
                strategy = raw_strategy.squeeze(0)
            
            # íƒí—˜/í™œìš© (Îµ-greedy)
            if training and np.random.random() < self.epsilon:
                # íƒí—˜: ëœë¤ ë…¸ì´ì¦ˆ ì¶”ê°€
                noise = torch.randn_like(strategy) * 0.1
                strategy = strategy + noise
                strategy = F.softmax(strategy, dim=0)  # ì¬ì •ê·œí™”
            
            # í•­ì²´ ê°•ë„ ê³„ì‚° (ì „ëµì˜ í™•ì‹ ë„)
            confidence = 1.0 - float(torch.std(strategy))  # ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ í™•ì‹ ë„ ë†’ìŒ
            self.antibody_strength = max(0.1, confidence)
            
            return strategy.numpy(), self.antibody_strength
            
        except Exception as e:
            print(f"í•­ì²´ ìƒì„± ì˜¤ë¥˜ ({self.risk_type}): {e}")
            # ê¸°ë³¸ ì „ëµ ë°˜í™˜
            default_strategy = np.ones(self.n_assets) / self.n_assets
            return default_strategy, 0.1

    def add_experience(self, market_features, crisis_level, action, reward):
        """ì—í”¼ì†Œë“œ ê²½í—˜ ì¶”ê°€"""
        experience = {
            'state': market_features.copy(),
            'crisis_level': crisis_level,
            'action': action.copy(),
            'reward': reward,
            'timestamp': datetime.now()
        }
        self.episode_buffer.append(experience)
        self.experience_count += 1

    def learn_from_batch(self):
        """ë°°ì¹˜ í•™ìŠµ ìˆ˜í–‰"""
        if len(self.episode_buffer) < self.batch_size:
            return
        
        try:
            # ë°°ì¹˜ ìƒ˜í”Œë§
            batch_size = min(self.batch_size, len(self.episode_buffer))
            batch = np.random.choice(self.episode_buffer, batch_size, replace=False)
            
            states = []
            actions = []
            rewards = []
            
            for exp in batch:
                # ìƒíƒœ êµ¬ì„±
                features_tensor = torch.FloatTensor(exp['state'])
                crisis_tensor = torch.FloatTensor([exp['crisis_level']])
                combined_state = torch.cat([features_tensor, crisis_tensor, self.specialization_weights])
                states.append(combined_state)
                
                # ì•¡ì…˜ê³¼ ë³´ìƒ
                actions.append(torch.FloatTensor(exp['action']))
                rewards.append(exp['reward'])
            
            # í…ì„œë¡œ ë³€í™˜
            states = torch.stack(states)
            actions = torch.stack(actions)
            rewards = torch.FloatTensor(rewards)
            
            # ë³´ìƒ ì •ê·œí™” (-1 ~ 1)
            if len(rewards) > 1:
                rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)
            
            # ìˆœì „íŒŒ
            predicted_actions = self.strategy_network(states)
            
            # Policy Gradient ì†ì‹¤
            log_probs = torch.log(predicted_actions + 1e-8)
            policy_loss = -torch.mean(log_probs * actions.unsqueeze(1) * rewards.unsqueeze(1))
            
            # ì—”íŠ¸ë¡œí”¼ ë³´ë„ˆìŠ¤ (íƒí—˜ ì¥ë ¤)
            entropy = -torch.mean(predicted_actions * torch.log(predicted_actions + 1e-8))
            entropy_bonus = 0.01 * entropy
            
            total_loss = policy_loss - entropy_bonus
            
            # ì—­ì „íŒŒ
            self.optimizer.zero_grad()
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.strategy_network.parameters(), 0.5)
            self.optimizer.step()
            
            # Îµ ê°ì†Œ
            self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)
            
        except Exception as e:
            print(f"ë°°ì¹˜ í•™ìŠµ ì˜¤ë¥˜ ({self.risk_type}): {e}")

    def end_episode(self):
        """ì—í”¼ì†Œë“œ ì¢…ë£Œ ë° í•™ìŠµ"""
        if len(self.episode_buffer) > 0:
            # ì—í”¼ì†Œë“œ ê²½í—˜ì„ ì „ì²´ ë²„í¼ì— ì¶”ê°€
            self.experience_buffer.extend(self.episode_buffer)
            
            # ë°°ì¹˜ í•™ìŠµ ìˆ˜í–‰
            if len(self.episode_buffer) >= self.batch_size:
                self.learn_from_batch()
            
            # ì—í”¼ì†Œë“œ ë²„í¼ ì´ˆê¸°í™”
            self.episode_buffer = []
            
            # ë²„í¼ í¬ê¸° ì œí•œ
            if len(self.experience_buffer) > 1000:
                self.experience_buffer = self.experience_buffer[-1000:]

    def learn_from_experience(self, market_features, crisis_level, effectiveness):
        """ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
        # ë‹¨ìˆœí™”ëœ í•™ìŠµ (ì¦‰ì‹œ í•™ìŠµ)
        if len(market_features) >= 8:
            dummy_action = np.ones(self.n_assets) / self.n_assets
            self.add_experience(market_features, crisis_level, dummy_action, effectiveness)
            
            # ì£¼ê¸°ì  ë°°ì¹˜ í•™ìŠµ
            if self.experience_count % self.update_frequency == 0:
                self.learn_from_batch()

    def adapt_response(self, antigen_pattern, effectiveness):
        """ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
        # ë‹¨ìˆœí™”ëœ í•™ìŠµ
        if len(antigen_pattern) >= 8:  # market_features í¬ê¸° í™•ì¸
            crisis_level = 0.5  # ê¸°ë³¸ê°’
            self.learn_from_experience(antigen_pattern, crisis_level, effectiveness)


class BCell(ImmuneCell):
    """ë ˆê±°ì‹œ B-ì„¸í¬: ê¸°ì¡´ í•˜ë“œì½”ë”© ì „ëµ (í˜¸í™˜ì„± ìœ ì§€)"""

    def __init__(self, cell_id, risk_type, response_strategy):
        super().__init__(cell_id)
        self.risk_type = risk_type  # 'volatility', 'correlation', 'momentum'
        self.response_strategy = response_strategy
        self.antibody_strength = 0.1

    def produce_antibody(self, antigen_pattern):
        """í•­ì› íŒ¨í„´ì— ë§ëŠ” í•­ì²´(ë°©ì–´ ì „ëµ) ìƒì„±"""
        # í•­ì›-í•­ì²´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        if hasattr(self, "learned_patterns"):
            similarities = [
                cosine_similarity([antigen_pattern], [pattern])[0][0]
                for pattern in self.learned_patterns
            ]
            max_similarity = max(similarities) if similarities else 0
        else:
            max_similarity = 0

        # í•­ì²´ ê°•ë„ ê³„ì‚°
        self.antibody_strength = min(1.0, max_similarity + 0.1)

        return self.antibody_strength

    def adapt_response(self, antigen_pattern, effectiveness):
        """ì ì‘ì  ë©´ì—­ ë°˜ì‘ í•™ìŠµ"""
        if not hasattr(self, "learned_patterns"):
            self.learned_patterns = []

        # íš¨ê³¼ì ì¸ íŒ¨í„´ì„ ê¸°ì–µì— ì €ì¥
        if effectiveness > 0.6:
            self.learned_patterns.append(antigen_pattern.copy())
            # ìµœëŒ€ 10ê°œ íŒ¨í„´ë§Œ ìœ ì§€
            if len(self.learned_patterns) > 10:
                self.learned_patterns.pop(0)


class MemoryCell:
    """ê¸°ì–µ ì„¸í¬: ê³¼ê±° ìœ„ê¸° íŒ¨í„´ ì €ì¥"""

    def __init__(self, max_memories=20):
        self.max_memories = max_memories
        self.crisis_memories = []  # (íŒ¨í„´, ëŒ€ì‘ì „ëµ, íš¨ê³¼)

    def store_memory(self, crisis_pattern, response_strategy, effectiveness):
        """ìœ„ê¸° ê¸°ì–µ ì €ì¥"""
        memory = {
            "pattern": crisis_pattern.copy(),
            "strategy": response_strategy.copy(),
            "effectiveness": effectiveness,
            "strength": 1.0,
        }

        self.crisis_memories.append(memory)

        # ë©”ëª¨ë¦¬ ìš©ëŸ‰ ê´€ë¦¬
        if len(self.crisis_memories) > self.max_memories:
            # íš¨ê³¼ê°€ ë‚®ì€ ê¸°ì–µë¶€í„° ì œê±°
            self.crisis_memories.sort(key=lambda x: x["effectiveness"])
            self.crisis_memories.pop(0)

    def recall_memory(self, current_pattern):
        """í˜„ì¬ íŒ¨í„´ê³¼ ìœ ì‚¬í•œ ê³¼ê±° ê¸°ì–µ íšŒìƒ"""
        if not self.crisis_memories:
            return None, 0.0

        similarities = []
        for memory in self.crisis_memories:
            similarity = cosine_similarity([current_pattern], [memory["pattern"]])[0][0]
            similarities.append(similarity * memory["effectiveness"])

        best_memory_idx = np.argmax(similarities)
        best_similarity = similarities[best_memory_idx]

        if best_similarity > 0.7:  # ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ê¸°ì–µ í™œìš©
            return self.crisis_memories[best_memory_idx], best_similarity

        return None, 0.0


class ImmunePortfolioSystem:
    """ìƒì²´ëª¨ë°© ë©´ì—­ í¬íŠ¸í´ë¦¬ì˜¤ ì‹œìŠ¤í…œ"""

    def __init__(self, n_assets, n_tcells=3, n_bcells=5, random_state=None, use_generative_bcells=True):
        self.n_assets = n_assets
        self.use_generative_bcells = use_generative_bcells

        # T-ì„¸í¬ë“¤ (ë‹¤ì–‘í•œ ë¯¼ê°ë„ë¡œ ìœ„í—˜ íƒì§€)
        # ê° T-ì„¸í¬ë§ˆë‹¤ ë‹¤ë¥¸ random_state ì‚¬ìš©
        self.tcells = [
            TCell(f"T{i}", sensitivity=0.05 + i * 0.02, 
                  random_state=None if random_state is None else random_state + i) 
            for i in range(n_tcells)
        ]

        # B-ì„¸í¬ë“¤ (ìœ„í—˜ ìœ í˜•ë³„ ëŒ€ì‘)
        if use_generative_bcells:
            # ìƒì„±í˜• B-ì„¸í¬ ì‚¬ìš© (ì‹ ê²½ë§ ê¸°ë°˜)
            feature_size = 8  # market_features í¬ê¸°
            input_size = feature_size + 1 + n_assets  # features + crisis_level + specialization
            
            self.bcells = [
                GenerativeBCell("GB1", "volatility", input_size, n_assets),
                GenerativeBCell("GB2", "correlation", input_size, n_assets),
                GenerativeBCell("GB3", "momentum", input_size, n_assets),
                GenerativeBCell("GB4", "liquidity", input_size, n_assets),
                GenerativeBCell("GB5", "macro", input_size, n_assets),
            ]
            print("ìƒì„±í˜• B-ì„¸í¬ ì‹œìŠ¤í…œ í™œì„±í™”ë¨")
        else:
            # ê¸°ì¡´ í•˜ë“œì½”ë”© B-ì„¸í¬ ì‚¬ìš©
            self.bcells = [
                BCell("B1", "volatility", self._volatility_response),
                BCell("B2", "correlation", self._correlation_response),
                BCell("B3", "momentum", self._momentum_response),
                BCell("B4", "liquidity", self._liquidity_response),
                BCell("B5", "macro", self._macro_response),
            ]
            print("ë ˆê±°ì‹œ B-ì„¸í¬ ì‹œìŠ¤í…œ í™œì„±í™”ë¨")

        # ê¸°ì–µ ì„¸í¬
        self.memory_cell = MemoryCell()

        # ê¸°ë³¸ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜
        self.base_weights = np.ones(n_assets) / n_assets
        self.current_weights = self.base_weights.copy()

        # ë©´ì—­ ì‹œìŠ¤í…œ ìƒíƒœ
        self.immune_activation = 0.0
        self.crisis_level = 0.0

    def extract_market_features(self, market_data, lookback=20):
        """ì‹œì¥ íŠ¹ì„± ì¶”ì¶œ (ê°•í™”ëœ NaN ì²˜ë¦¬)"""
        if len(market_data) < lookback:
            return np.zeros(8)  # ê¸°ë³¸ íŠ¹ì„± ë²¡í„°

        returns = market_data.pct_change().dropna()
        if len(returns) == 0:
            return np.zeros(8)

        recent_returns = returns.iloc[-lookback:]
        if len(recent_returns) == 0:
            return np.zeros(8)

        # NaN ì•ˆì „ ê³„ì‚°ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
        def safe_mean(x):
            if len(x) == 0 or x.isnull().all():
                return 0.0
            return x.mean() if not np.isnan(x.mean()) else 0.0

        def safe_std(x):
            if len(x) == 0 or x.isnull().all():
                return 0.0
            return x.std() if not np.isnan(x.std()) else 0.0

        def safe_corr(x):
            try:
                if len(x) <= 1 or x.isnull().all().all():
                    return 0.0
                corr_matrix = np.corrcoef(x.T)
                if np.isnan(corr_matrix).any():
                    return 0.0
                return np.mean(corr_matrix[~np.eye(corr_matrix.shape[0], dtype=bool)])
            except:
                return 0.0

        def safe_skew(x):
            try:
                skew_vals = x.skew()
                if skew_vals.isnull().all():
                    return 0.0
                return skew_vals.mean() if not np.isnan(skew_vals.mean()) else 0.0
            except:
                return 0.0

        def safe_kurtosis(x):
            try:
                kurt_vals = x.kurtosis()
                if kurt_vals.isnull().all():
                    return 0.0
                return kurt_vals.mean() if not np.isnan(kurt_vals.mean()) else 0.0
            except:
                return 0.0

        features = [
            safe_std(recent_returns.std()),  # í‰ê·  ë³€ë™ì„±
            safe_corr(recent_returns),  # í‰ê·  ìƒê´€ê´€ê³„
            safe_mean(recent_returns.mean()),  # í‰ê·  ìˆ˜ìµë¥ 
            safe_skew(recent_returns),  # í‰ê·  ì™œë„
            safe_kurtosis(recent_returns),  # í‰ê·  ì²¨ë„
            safe_std(recent_returns.std()),  # ë³€ë™ì„±ì˜ ë³€ë™ì„±
            len(recent_returns[recent_returns.sum(axis=1) < -0.02])
            / max(len(recent_returns), 1),  # í•˜ë½ì¼ ë¹„ìœ¨
            (
                max(recent_returns.max().max() - recent_returns.min().min(), 0)
                if not recent_returns.empty
                else 0
            ),  # ìˆ˜ìµë¥  ë²”ìœ„
        ]

        # NaN ë° ë¬´í•œëŒ€ ê°’ ìµœì¢… ì²˜ë¦¬
        features = np.array(features)
        features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)

        return features

    def _volatility_response(self, activation_level):
        """ë³€ë™ì„± ìœ„í—˜ ëŒ€ì‘ ì „ëµ"""
        # ë³€ë™ì„±ì´ ë†’ì„ ë•Œ ì•ˆì „ ìì‚° ë¹„ì¤‘ ì¦ê°€
        risk_reduction = activation_level * 0.3
        weights = self.base_weights * (1 - risk_reduction)
        # ì•ˆì „ ìì‚°(JPM, JNJ, PG)ì— ì¶”ê°€ ë°°ë¶„
        safe_indices = [6, 7, 8]  # JPM, JNJ, PG
        for idx in safe_indices:
            if idx < len(weights):
                weights[idx] += risk_reduction / len(safe_indices)
        return weights / np.sum(weights)

    def _correlation_response(self, activation_level):
        """ìƒê´€ê´€ê³„ ìœ„í—˜ ëŒ€ì‘ ì „ëµ"""
        # ìƒê´€ê´€ê³„ê°€ ë†’ì„ ë•Œ ë¶„ì‚° ê°•í™”
        diversification_boost = activation_level * 0.2
        weights = self.base_weights.copy()
        # ê°€ì¥ ìƒê´€ê´€ê³„ê°€ ë‚®ì€ ìì‚°ì— ì¶”ê°€ ë°°ë¶„
        weights = weights * (1 - diversification_boost) + diversification_boost / len(
            weights
        )
        return weights / np.sum(weights)

    def _momentum_response(self, activation_level):
        """ëª¨ë©˜í…€ ìœ„í—˜ ëŒ€ì‘ ì „ëµ"""
        # ëª¨ë©˜í…€ ê¸‰ë³€ ì‹œ ì¤‘ë¦½ í¬ì§€ì…˜ìœ¼ë¡œ ë³µê·€
        neutral_adjustment = activation_level * 0.25
        weights = self.base_weights * (1 - neutral_adjustment) + (
            self.base_weights * neutral_adjustment
        )
        return weights / np.sum(weights)

    def _liquidity_response(self, activation_level):
        """ìœ ë™ì„± ìœ„í—˜ ëŒ€ì‘ ì „ëµ"""
        # ìœ ë™ì„± ìœ„í—˜ ì‹œ ëŒ€í˜•ì£¼ ë¹„ì¤‘ ì¦ê°€
        large_cap_boost = activation_level * 0.2
        weights = self.base_weights.copy()
        # ëŒ€í˜•ì£¼ (AAPL, MSFT, AMZN, GOOGL) ë¹„ì¤‘ ì¦ê°€
        large_cap_indices = [0, 1, 2, 3]
        for idx in large_cap_indices:
            if idx < len(weights):
                weights[idx] += large_cap_boost / len(large_cap_indices)
        return weights / np.sum(weights)

    def _macro_response(self, activation_level):
        """ê±°ì‹œê²½ì œ ìœ„í—˜ ëŒ€ì‘ ì „ëµ"""
        # ê±°ì‹œê²½ì œ ë¶ˆì•ˆ ì‹œ ë°©ì–´ì£¼ ë¹„ì¤‘ ì¦ê°€
        defensive_boost = activation_level * 0.3
        weights = self.base_weights * (1 - defensive_boost)
        # ë°©ì–´ì£¼ (JNJ, PG, V) ë¹„ì¤‘ ì¦ê°€
        defensive_indices = [7, 8, 9]
        for idx in defensive_indices:
            if idx < len(weights):
                weights[idx] += defensive_boost / len(defensive_indices)
        return weights / np.sum(weights)

    def pretrain_bcells(self, market_data, episodes=50):
        """ìƒì„±í˜• B-ì„¸í¬ ì‚¬ì „ í›ˆë ¨"""
        if not self.use_generative_bcells:
            return
        
        print(f"ìƒì„±í˜• B-ì„¸í¬ ì‚¬ì „ í›ˆë ¨ ì‹œì‘ ({episodes} ì—í”¼ì†Œë“œ)")
        
        # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
        returns = market_data.pct_change().dropna()
        
        for episode in tqdm(range(episodes), desc="ì‚¬ì „ í›ˆë ¨ ì—í”¼ì†Œë“œ"):
            # ì—í”¼ì†Œë“œ ì‹œì‘
            episode_length = min(50, len(returns) - 20)  # ìµœëŒ€ 50ì¼
            start_idx = np.random.randint(20, len(returns) - episode_length)
            
            for step in range(episode_length):
                current_idx = start_idx + step
                
                # í˜„ì¬ ì‹œì ê¹Œì§€ì˜ ë°ì´í„°ë¡œ íŠ¹ì„± ì¶”ì¶œ
                current_data = market_data.iloc[:current_idx+1]
                market_features = self.extract_market_features(current_data)
                
                # T-ì„¸í¬ ìœ„í—˜ íƒì§€
                crisis_level = np.random.uniform(0.2, 0.8)  # ë‹¤ì–‘í•œ ìœ„í—˜ ìˆ˜ì¤€ ì‹œë®¬ë ˆì´ì…˜
                
                # ê° B-ì„¸í¬ì—ì„œ ì „ëµ ìƒì„± (í›ˆë ¨ ëª¨ë“œ)
                for bcell in self.bcells:
                    strategy, _ = bcell.produce_antibody(market_features, crisis_level, training=True)
                    
                    # ì‹¤ì œ ìˆ˜ìµë¥ ë¡œ ë³´ìƒ ê³„ì‚°
                    if current_idx + 1 < len(returns):
                        actual_returns = returns.iloc[current_idx + 1]
                        portfolio_return = np.sum(strategy * actual_returns)
                        
                        # ë³´ìƒ ê³„ì‚° (ìˆ˜ìµë¥  + ìœ„í—˜ ì¡°ì •)
                        reward = portfolio_return - 0.5 * abs(portfolio_return)  # ë³€ë™ì„± í˜ë„í‹°
                        reward = max(-1, min(1, reward * 10))  # -1 ~ 1 ë²”ìœ„ë¡œ ì •ê·œí™”
                        
                        # ê²½í—˜ ì¶”ê°€
                        bcell.add_experience(market_features, crisis_level, strategy, reward)
            
            # ì—í”¼ì†Œë“œ ì¢…ë£Œ ë° í•™ìŠµ
            for bcell in self.bcells:
                bcell.end_episode()
        
        print("ì‚¬ì „ í›ˆë ¨ ì™„ë£Œ")

    def immune_response(self, market_features, training=False):
        """ë©´ì—­ ë°˜ì‘ ì‹¤í–‰ (ìƒì„±í˜• B-ì„¸í¬ ì§€ì›)"""
        # 1. T-ì„¸í¬ í™œì„±í™” (ìœ„í—˜ íƒì§€)
        tcell_activations = []
        for tcell in self.tcells:
            activation = tcell.detect_anomaly(market_features.reshape(1, -1))
            tcell_activations.append(activation)

        # ì „ì²´ ìœ„í—˜ ìˆ˜ì¤€ ê³„ì‚°
        self.crisis_level = np.mean(tcell_activations)

        # 2. ê¸°ì–µ ì„¸í¬ í™•ì¸
        recalled_memory, memory_strength = self.memory_cell.recall_memory(
            market_features
        )

        if recalled_memory and memory_strength > 0.8:
            # ê°•í•œ ê¸°ì–µì´ ìˆìœ¼ë©´ ì¦‰ì‹œ ëŒ€ì‘
            return recalled_memory["strategy"], "memory_response"

        # 3. B-ì„¸í¬ í™œì„±í™” (ìœ„í—˜ ëŒ€ì‘)
        if self.crisis_level > 0.3:  # ìœ„í—˜ ì„ê³„ê°’
            
            if self.use_generative_bcells:
                # ìƒì„±í˜• B-ì„¸í¬ ì‚¬ìš©
                response_weights = []
                antibody_strengths = []

                for bcell in self.bcells:
                    strategy, antibody_strength = bcell.produce_antibody(
                        market_features, self.crisis_level, training=training
                    )
                    response_weights.append(strategy)
                    antibody_strengths.append(antibody_strength)

                # í˜‘ë ¥ì  ì•™ìƒë¸”: í•­ì²´ ê°•ë„ì— ë”°ë¥¸ ê°€ì¤‘ í‰ê· 
                if len(antibody_strengths) > 0 and sum(antibody_strengths) > 0:
                    # ì •ê·œí™”ëœ ê°€ì¤‘ì¹˜ ê³„ì‚°
                    normalized_strengths = np.array(antibody_strengths) / sum(antibody_strengths)
                    
                    # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì „ëµ ê²°í•©
                    ensemble_strategy = np.zeros(self.n_assets)
                    for i, (strategy, weight) in enumerate(zip(response_weights, normalized_strengths)):
                        ensemble_strategy += strategy * weight
                    
                    # ì •ê·œí™”
                    ensemble_strategy = ensemble_strategy / np.sum(ensemble_strategy)
                    
                    self.immune_activation = np.mean(antibody_strengths)
                    
                    # ê°€ì¥ ê¸°ì—¬ë„ê°€ ë†’ì€ B-ì„¸í¬ ì°¾ê¸°
                    dominant_bcell_idx = np.argmax(antibody_strengths)
                    response_type = f"generative_ensemble_{self.bcells[dominant_bcell_idx].risk_type}"
                    
                    return ensemble_strategy, response_type
                else:
                    return self.base_weights, "generative_fallback"
            
            else:
                # ê¸°ì¡´ í•˜ë“œì½”ë”© B-ì„¸í¬ ì‚¬ìš©
                response_weights = []
                antibody_strengths = []

                for bcell in self.bcells:
                    antibody_strength = bcell.produce_antibody(market_features)
                    response_weight = bcell.response_strategy(
                        self.crisis_level * antibody_strength
                    )
                    response_weights.append(response_weight)
                    antibody_strengths.append(antibody_strength)

                # ê°€ì¥ ê°•í•œ í•­ì²´ ë°˜ì‘ ì„ íƒ
                best_response_idx = np.argmax(antibody_strengths)
                self.immune_activation = antibody_strengths[best_response_idx]

                return (
                    response_weights[best_response_idx],
                    f"legacy_bcell_{self.bcells[best_response_idx].risk_type}",
                )

        # ìœ„í—˜ ìˆ˜ì¤€ì´ ë‚®ìœ¼ë©´ ê¸°ë³¸ ê°€ì¤‘ì¹˜ ìœ ì§€
        return self.base_weights, "normal"

    def update_memory(self, crisis_pattern, response_strategy, effectiveness):
        """ë©´ì—­ ê¸°ì–µ ì—…ë°ì´íŠ¸ (ìƒì„±í˜• B-ì„¸í¬ í•™ìŠµ ì§€ì›)"""
        self.memory_cell.store_memory(crisis_pattern, response_strategy, effectiveness)

        # B-ì„¸í¬ ì ì‘
        if self.use_generative_bcells:
            # ìƒì„±í˜• B-ì„¸í¬ í•™ìŠµ
            for bcell in self.bcells:
                bcell.learn_from_experience(crisis_pattern, self.crisis_level, effectiveness)
        else:
            # ê¸°ì¡´ B-ì„¸í¬ ì ì‘
            for bcell in self.bcells:
                bcell.adapt_response(crisis_pattern, effectiveness)


class ImmunePortfolioBacktester:
    def __init__(self, symbols, train_start, train_end, test_start, test_end):
        self.symbols = symbols
        self.train_start = train_start
        self.train_end = train_end
        self.test_start = test_start
        self.test_end = test_end

        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        data_filename = f"market_data_{'_'.join(symbols)}_{train_start}_{test_end}.pkl"
        self.data_path = os.path.join(DATA_DIR, data_filename)

        # ë°ì´í„° ë¡œë“œ ë˜ëŠ” ë‹¤ìš´ë¡œë“œ
        if os.path.exists(self.data_path):
            print(f"ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì¤‘: {data_filename}")
            with open(self.data_path, "rb") as f:
                self.data = pickle.load(f)
        else:
            print("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
            raw_data = yf.download(
                symbols, start="2007-12-01", end="2025-01-01", progress=True
            )

            # ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° ì ì ˆí•œ ì»¬ëŸ¼ ì„ íƒ
            if len(symbols) == 1:
                # ë‹¨ì¼ í‹°ì»¤ì¸ ê²½ìš°
                if "Adj Close" in raw_data.columns:
                    self.data = raw_data["Adj Close"].to_frame(symbols[0])
                elif "Close" in raw_data.columns:
                    self.data = raw_data["Close"].to_frame(symbols[0])
                    print("ì£¼ì˜: 'Adj Close' ì—†ìŒ, 'Close' ì‚¬ìš©")
                else:
                    raise ValueError("ê°€ê²© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ë‹¤ì¤‘ í‹°ì»¤ì¸ ê²½ìš°
                try:
                    # Adj Close ì‹œë„
                    self.data = raw_data["Adj Close"]
                except KeyError:
                    try:
                        # Close ì‹œë„
                        self.data = raw_data["Close"]
                        print("ì£¼ì˜: 'Adj Close' ì—†ìŒ, 'Close' ì‚¬ìš©")
                    except KeyError:
                        # MultiIndex êµ¬ì¡°ì¸ ê²½ìš° ê°œë³„ ì²˜ë¦¬
                        price_data = {}
                        for symbol in symbols:
                            if ("Adj Close", symbol) in raw_data.columns:
                                price_data[symbol] = raw_data[("Adj Close", symbol)]
                            elif ("Close", symbol) in raw_data.columns:
                                price_data[symbol] = raw_data[("Close", symbol)]
                                print(f"ì£¼ì˜: {symbol} 'Adj Close' ì—†ìŒ, 'Close' ì‚¬ìš©")
                            else:
                                print(f"ê²½ê³ : {symbol} ê°€ê²© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                continue

                        if not price_data:
                            raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ê°€ê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

                        self.data = pd.DataFrame(price_data)

            # ê°•í™”ëœ ê²°ì¸¡ê°’ ì²˜ë¦¬
            print("ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")

            # 1ì°¨ ì²˜ë¦¬: Forward Fill â†’ Backward Fill
            if self.data.isnull().values.any():
                print("ê²°ì¸¡ê°’ ë°œê²¬, ì „ë°©í–¥/í›„ë°©í–¥ ì±„ìš°ê¸° ì ìš©")
                self.data = self.data.fillna(method="ffill").fillna(method="bfill")

            # 2ì°¨ ì²˜ë¦¬: ì—¬ì „íˆ NaNì´ ë‚¨ì•„ìˆìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€
            if self.data.isnull().values.any():
                print("ì”ì—¬ ê²°ì¸¡ê°’ì„ 0ìœ¼ë¡œ ì±„ì›€")
                self.data = self.data.fillna(0)

            # 3ì°¨ ì²˜ë¦¬: ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬
            if np.isinf(self.data.values).any():
                print("ë¬´í•œëŒ€ ê°’ ë°œê²¬, ìœ í•œê°’ìœ¼ë¡œ ë³€í™˜")
                self.data = self.data.replace([np.inf, -np.inf], 0)

            # ìµœì¢… ê²€ì¦
            if self.data.isnull().values.any() or np.isinf(self.data.values).any():
                print("ìµœì¢… ë°ì´í„° ì •ë¦¬ ì¤‘...")
                self.data = pd.DataFrame(
                    np.nan_to_num(self.data.values, nan=0.0, posinf=0.0, neginf=0.0),
                    index=self.data.index,
                    columns=self.data.columns,
                )

            # ë°ì´í„° ì €ì¥
            with open(self.data_path, "wb") as f:
                pickle.dump(self.data, f)
            print(f"ë°ì´í„° ì €ì¥ ì™„ë£Œ: {data_filename}")

        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
        self.train_data = self.data[train_start:train_end]
        self.test_data = self.data[test_start:test_end]

    def calculate_metrics(self, returns, initial_capital=1e6):
        """ì„±ê³¼ ì§€í‘œ ê³„ì‚°"""
        # ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
        cum_returns = (1 + returns).cumprod()
        final_value = initial_capital * cum_returns.iloc[-1]
        total_return = (final_value - initial_capital) / initial_capital

        # ì—°ê°„í™”ëœ ì§€í‘œë“¤
        volatility = returns.std() * np.sqrt(252)
        max_drawdown = self.calculate_max_drawdown(returns)

        # Sharpe Ratio (ë¬´ìœ„í—˜ ìˆ˜ìµë¥  0 ê°€ì •)
        sharpe_ratio = (
            returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0
        )

        # Calmar Ratio
        calmar_ratio = (
            returns.mean() * 252 / abs(max_drawdown) if max_drawdown != 0 else 0
        )

        return {
            "Total Return": total_return,
            "Volatility": volatility,
            "Max Drawdown": max_drawdown,
            "Sharpe Ratio": sharpe_ratio,
            "Calmar Ratio": calmar_ratio,
            "Final Value": final_value,
            "Initial Capital": initial_capital,
        }

    def calculate_max_drawdown(self, returns):
        """ìµœëŒ€ ë‚™í­ ê³„ì‚°"""
        cum_returns = (1 + returns).cumprod()
        running_max = cum_returns.expanding().max()
        drawdown = (cum_returns - running_max) / running_max
        return drawdown.min()

    def backtest_single_run(self, seed=None, return_model=False, use_generative_bcells=True):
        """ë‹¨ì¼ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        if seed is not None:
            np.random.seed(seed)
            if use_generative_bcells:
                torch.manual_seed(seed)

        immune_system = ImmunePortfolioSystem(
            n_assets=len(self.symbols), 
            random_state=seed,
            use_generative_bcells=use_generative_bcells
        )

        # ì‚¬ì „ í›ˆë ¨ ë‹¨ê³„ (ìƒì„±í˜• B-ì„¸í¬ë§Œ)
        if use_generative_bcells:
            print("ì‚¬ì „ í›ˆë ¨ ë‹¨ê³„...")
            immune_system.pretrain_bcells(self.train_data, episodes=100)
        
        # í›ˆë ¨ ë‹¨ê³„ (ë©´ì—­ ì‹œìŠ¤í…œ í›ˆë ¨)
        print("ì˜¨ë¼ì¸ í•™ìŠµ ë‹¨ê³„...")
        train_returns = self.train_data.pct_change().dropna()
        portfolio_values = [1.0]

        for i in tqdm(range(len(train_returns)), desc="í›ˆë ¨ ì§„í–‰"):
            current_data = self.train_data.iloc[: i + 1]

            # ì‹œì¥ íŠ¹ì„± ì¶”ì¶œ
            market_features = immune_system.extract_market_features(current_data)

            # ë©´ì—­ ë°˜ì‘ ì‹¤í–‰ (í›ˆë ¨ ëª¨ë“œ)
            weights, response_type = immune_system.immune_response(market_features, training=True)

            # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
            portfolio_return = np.sum(weights * train_returns.iloc[i])
            portfolio_values.append(portfolio_values[-1] * (1 + portfolio_return))

            # ë©´ì—­ ì‹œìŠ¤í…œ íš¨ê³¼ì„± í‰ê°€ ë° í•™ìŠµ
            if len(portfolio_values) > 20:
                recent_returns = (
                    np.diff(portfolio_values[-21:]) / portfolio_values[-21:-1]
                )
                effectiveness = np.mean(recent_returns) / (
                    np.std(recent_returns) + 1e-6
                )
                effectiveness = max(0, min(1, (effectiveness + 1) / 2))  # 0~1 ì •ê·œí™”

                # ìœ„ê¸° ìƒí™©ì—ì„œëŠ” ê¸°ì–µ ì„¸í¬ì—ë§Œ ì €ì¥
                if immune_system.crisis_level > 0.3:
                    immune_system.update_memory(market_features, weights, effectiveness)

                # ìƒì„±í˜• B-ì„¸í¬ëŠ” ëª¨ë“  ìƒí™©ì—ì„œ í•™ìŠµ
                if use_generative_bcells:
                    for bcell in immune_system.bcells:
                        bcell.add_experience(market_features, immune_system.crisis_level, weights, effectiveness)

        # í›ˆë ¨ ì™„ë£Œ í›„ ì—í”¼ì†Œë“œ ì¢…ë£Œ
        if use_generative_bcells:
            print("í›ˆë ¨ ì™„ë£Œ, ëª¨ë¸ ìµœì¢… ì—…ë°ì´íŠ¸...")
            for bcell in immune_system.bcells:
                bcell.end_episode()

        # í…ŒìŠ¤íŠ¸ ë‹¨ê³„ (í‰ê°€ ëª¨ë“œ)
        print("í…ŒìŠ¤íŠ¸ ë‹¨ê³„...")
        test_returns = self.test_data.pct_change().dropna()
        test_portfolio_returns = []

        for i in tqdm(range(len(test_returns)), desc="í…ŒìŠ¤íŠ¸ ì§„í–‰"):
            current_data = self.test_data.iloc[: i + 1]

            # ì‹œì¥ íŠ¹ì„± ì¶”ì¶œ
            market_features = immune_system.extract_market_features(current_data)

            # ë©´ì—­ ë°˜ì‘ ì‹¤í–‰ (í‰ê°€ ëª¨ë“œ, íƒí—˜ ì—†ìŒ)
            weights, response_type = immune_system.immune_response(market_features, training=False)

            # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
            portfolio_return = np.sum(weights * test_returns.iloc[i])
            test_portfolio_returns.append(portfolio_return)

        if return_model:
            return (
                pd.Series(test_portfolio_returns, index=test_returns.index),
                immune_system,
            )
        else:
            return pd.Series(test_portfolio_returns, index=test_returns.index)

    def save_model(self, immune_system, filename=None):
        """ë©´ì—­ ì‹œìŠ¤í…œ ëª¨ë¸ ì €ì¥ (PyTorch ëª¨ë¸ ì§€ì›)"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            if immune_system.use_generative_bcells:
                filename = f"generative_immune_system_{timestamp}"
            else:
                filename = f"legacy_immune_system_{timestamp}.pkl"
        
        if immune_system.use_generative_bcells:
            # ìƒì„±í˜• B-ì„¸í¬ í¬í•¨ ëª¨ë¸ ì €ì¥
            model_dir = os.path.join(MODELS_DIR, filename)
            os.makedirs(model_dir, exist_ok=True)
            
            # ê° ìƒì„±í˜• B-ì„¸í¬ì˜ ì‹ ê²½ë§ ì €ì¥
            for i, bcell in enumerate(immune_system.bcells):
                if hasattr(bcell, 'strategy_network'):
                    network_path = os.path.join(model_dir, f"bcell_{i}_{bcell.risk_type}.pth")
                    torch.save(bcell.strategy_network.state_dict(), network_path)
            
            # ê¸°íƒ€ ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥
            system_state = {
                'n_assets': immune_system.n_assets,
                'base_weights': immune_system.base_weights,
                'memory_cell': immune_system.memory_cell,
                'tcells': immune_system.tcells,
                'use_generative_bcells': True
            }
            state_path = os.path.join(model_dir, "system_state.pkl")
            with open(state_path, "wb") as f:
                pickle.dump(system_state, f)
            
            print(f"ìƒì„±í˜• ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_dir}")
            return model_dir
        else:
            # ê¸°ì¡´ ë°©ì‹ ì €ì¥
            model_path = os.path.join(MODELS_DIR, filename)
            with open(model_path, "wb") as f:
                pickle.dump(immune_system, f)
            print(f"ë ˆê±°ì‹œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filename}")
            return model_path

    def load_model(self, filename):
        """ë©´ì—­ ì‹œìŠ¤í…œ ëª¨ë¸ ë¡œë“œ"""
        model_path = os.path.join(MODELS_DIR, filename)
        if os.path.exists(model_path):
            with open(model_path, "rb") as f:
                immune_system = pickle.load(f)
            print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {filename}")
            return immune_system
        else:
            print(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")
            return None

    def save_results(self, metrics_df, filename=None):
        """ê²°ê³¼ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"bipd_results_{timestamp}"

        # CSV ì €ì¥
        csv_path = os.path.join(RESULTS_DIR, f"{filename}.csv")
        metrics_df.to_csv(csv_path, index=False)

        # ì‹œê°í™” ë° ì €ì¥
        plt.figure(figsize=(15, 10))

        # ì„œë¸Œí”Œë¡¯ 1: ì„±ê³¼ ì§€í‘œ ë°•ìŠ¤í”Œë¡¯
        plt.subplot(2, 3, 1)
        metrics_df.boxplot(column=["Total Return"], ax=plt.gca())
        plt.title("Total Return Distribution")

        plt.subplot(2, 3, 2)
        metrics_df.boxplot(column=["Sharpe Ratio"], ax=plt.gca())
        plt.title("Sharpe Ratio Distribution")

        plt.subplot(2, 3, 3)
        metrics_df.boxplot(column=["Max Drawdown"], ax=plt.gca())
        plt.title("Max Drawdown Distribution")

        # ì„œë¸Œí”Œë¡¯ 2: ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
        plt.subplot(2, 2, 3)
        correlation = metrics_df.corr()
        plt.imshow(correlation, cmap="coolwarm", aspect="auto")
        plt.colorbar()
        plt.title("Metrics Correlation")
        plt.xticks(range(len(correlation.columns)), correlation.columns, rotation=45)
        plt.yticks(range(len(correlation.columns)), correlation.columns)

        # ì„œë¸Œí”Œë¡¯ 3: ì„±ê³¼ ìš”ì•½
        plt.subplot(2, 2, 4)
        plt.axis("off")
        summary_text = f"""
        BIPD ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
        
        ì´ ìˆ˜ìµë¥ : {metrics_df['Total Return'].mean():.2%}
        í‘œì¤€í¸ì°¨: {metrics_df['Volatility'].mean():.3f}
        ìµœëŒ€ ë‚™í­: {metrics_df['Max Drawdown'].mean():.2%}
        Sharpe Ratio: {metrics_df['Sharpe Ratio'].mean():.2f}
        Calmar Ratio: {metrics_df['Calmar Ratio'].mean():.2f}
        ì´ˆê¸° ìë³¸: {metrics_df['Initial Capital'].iloc[0]:,.0f}ì›
        ìµœì¢… ìë³¸: {metrics_df['Final Value'].mean():,.0f}ì›
        """
        plt.text(0.1, 0.5, summary_text, fontsize=10, verticalalignment="center")

        plt.tight_layout()
        plot_path = os.path.join(RESULTS_DIR, f"{filename}.png")
        plt.savefig(plot_path, dpi=300, bbox_inches="tight")
        plt.close()

        print(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_path}, {plot_path}")
        return csv_path, plot_path

    def run_multiple_backtests(self, n_runs=10, save_results=True, use_generative_bcells=True):
        """ë‹¤ì¤‘ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        all_metrics = []
        best_immune_system = None
        best_sharpe = -np.inf

        print(f"\nBIPD ë°±í…ŒìŠ¤íŠ¸ {n_runs}íšŒ ì‹¤í–‰ ì¤‘...")
        if use_generative_bcells:
            print("ìƒì„±í˜• B-ì„¸í¬ ì‹œìŠ¤í…œ ì‚¬ìš©")
        else:
            print("ë ˆê±°ì‹œ B-ì„¸í¬ ì‹œìŠ¤í…œ ì‚¬ìš©")

        for run in range(n_runs):
            print(f"Run {run + 1}/{n_runs}")

            # ê° ì‹¤í–‰ë§ˆë‹¤ ë‹¤ë¥¸ ì‹œë“œ ì‚¬ìš©
            portfolio_returns, immune_system = self.backtest_single_run(
                seed=run, return_model=True, use_generative_bcells=use_generative_bcells
            )
            metrics = self.calculate_metrics(portfolio_returns)
            all_metrics.append(metrics)

            # ìµœê³  ì„±ê³¼ ëª¨ë¸ ì €ì¥
            if metrics["Sharpe Ratio"] > best_sharpe:
                best_sharpe = metrics["Sharpe Ratio"]
                best_immune_system = immune_system

        # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
        metrics_df = pd.DataFrame(all_metrics)

        system_type = "ìƒì„±í˜•" if use_generative_bcells else "ë ˆê±°ì‹œ"
        print(f"\n=== BIPD ({system_type}) ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
        print(f"ì´ ìˆ˜ìµë¥ : {metrics_df['Total Return'].mean():.2%}")
        print(f"í‘œì¤€í¸ì°¨: {metrics_df['Volatility'].mean():.3f}")
        print(f"ìµœëŒ€ ë‚™í­: {metrics_df['Max Drawdown'].mean():.2%}")
        print(f"Sharpe Ratio: {metrics_df['Sharpe Ratio'].mean():.2f}")
        print(f"Calmar Ratio: {metrics_df['Calmar Ratio'].mean():.2f}")
        print(f"ì´ˆê¸° ìë³¸: {metrics_df['Initial Capital'].iloc[0]:,.0f}ì›")
        print(f"ìµœì¢… ìë³¸: {metrics_df['Final Value'].mean():,.0f}ì›")

        # ê²°ê³¼ ì €ì¥
        if save_results:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_filename = f"bipd_{system_type}_{timestamp}"
            self.save_results(metrics_df, result_filename)
            
            if best_immune_system is not None:
                if use_generative_bcells:
                    model_filename = f"best_generative_immune_system_{timestamp}"
                else:
                    model_filename = "best_legacy_immune_system.pkl"
                self.save_model(best_immune_system, model_filename)

        return metrics_df


# ì‹¤í–‰
if __name__ == "__main__":
    # ì„¤ì •
    symbols = ["AAPL", "MSFT", "AMZN", "GOOGL", "NVDA", "TSLA", "JPM", "JNJ", "PG", "V"]
    train_start = "2008-01-02"
    train_end = "2020-12-31"
    test_start = "2021-01-01"
    test_end = "2024-12-31"

    # ì „ì—­ ì‹œë“œ ì´ˆê¸°í™” (ë§¤ë²ˆ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ìœ„í•´)
    import time
    global_seed = int(time.time()) % 10000
    np.random.seed(global_seed)
    torch.manual_seed(global_seed)
    print(f"ğŸ² Global random seed: {global_seed}")

    # ë°±í…ŒìŠ¤í„° ì´ˆê¸°í™”
    backtester = ImmunePortfolioBacktester(
        symbols, train_start, train_end, test_start, test_end
    )
    
    # ìƒì„±í˜• B-ì„¸í¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("\n" + "="*60)
    print("BIPD ìƒì„±í˜• B-ì„¸í¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    try:
        generative_results = backtester.run_multiple_backtests(
            n_runs=3,  # ì‚¬ì „ í›ˆë ¨ ë•Œë¬¸ì— ì ì€ íšŸìˆ˜ë¡œ í…ŒìŠ¤íŠ¸
            save_results=True, 
            use_generative_bcells=True
        )
        
        print("\nìƒì„±í˜• B-ì„¸í¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
        # ì˜µì…˜: ë ˆê±°ì‹œ ì‹œìŠ¤í…œê³¼ ë¹„êµ
        print("\n" + "="*60)
        print("ë ˆê±°ì‹œ ì‹œìŠ¤í…œê³¼ ì„±ëŠ¥ ë¹„êµ")
        print("="*60)
        
        legacy_results = backtester.run_multiple_backtests(
            n_runs=3,  # ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´ ë™ì¼í•œ íšŸìˆ˜
            save_results=True,
            use_generative_bcells=False
        )
        
        # ì„±ëŠ¥ ë¹„êµ ì¶œë ¥
        print("\nì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
        print(f"ìƒì„±í˜• B-ì„¸í¬ Sharpe Ratio: {generative_results['Sharpe Ratio'].mean():.3f}")
        print(f"ë ˆê±°ì‹œ B-ì„¸í¬ Sharpe Ratio: {legacy_results['Sharpe Ratio'].mean():.3f}")
        
        improvement = ((generative_results['Sharpe Ratio'].mean() - legacy_results['Sharpe Ratio'].mean()) 
                      / legacy_results['Sharpe Ratio'].mean() * 100)
        print(f"ì„±ëŠ¥ ê°œì„ : {improvement:+.1f}%")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ë ˆê±°ì‹œ ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤...")
        
        # ì˜¤ë¥˜ ì‹œ ë ˆê±°ì‹œ ì‹œìŠ¤í…œ ì‚¬ìš©
        legacy_results = backtester.run_multiple_backtests(
            n_runs=10,
            save_results=True,
            use_generative_bcells=False
        )
