# tests/debug_environment.py - í™˜ê²½ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸

import os
import sys
import warnings

warnings.filterwarnings("ignore")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

from config import *
from data import DataLoader
from core.environment import PortfolioEnvironment
from data.features import FeatureExtractor


def debug_environment():
    """í™˜ê²½ì˜ ì‹¤ì œ ë™ì‘ì„ ë””ë²„ê¹…"""

    print("=" * 80)
    print("í™˜ê²½ ë””ë²„ê¹… ì‹œì‘")
    print("=" * 80)

    # 1. ë°ì´í„° ë¡œë“œ (ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ìš©)
    print("[1] í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±...")
    dates = pd.date_range("2020-01-01", periods=100, freq="D")
    symbols = SYMBOLS[:5]  # 5ê°œ ì¢…ëª©ë§Œ ì‚¬ìš©

    # ë” í˜„ì‹¤ì ì¸ ê°€ê²© ë°ì´í„° ìƒì„±
    np.random.seed(42)
    returns = np.random.normal(0.0005, 0.02, (100, 5))  # ì¼ì¼ í‰ê·  0.05%, ë³€ë™ì„± 2%
    prices = pd.DataFrame(
        np.cumprod(1 + returns, axis=0) * 100, index=dates, columns=symbols
    )

    print(f"ê°€ê²© ë°ì´í„° ìƒì„± ì™„ë£Œ: {prices.shape}")
    print(f"ê°€ê²© ë²”ìœ„: {prices.min().min():.2f} ~ {prices.max().max():.2f}")

    # 2. í™˜ê²½ ì´ˆê¸°í™”
    print("\n[2] í™˜ê²½ ì´ˆê¸°í™”...")
    feature_extractor = FeatureExtractor(lookback_window=LOOKBACK_WINDOW)
    env = PortfolioEnvironment(
        price_data=prices,
        feature_extractor=feature_extractor,
        initial_capital=100000,  # ì‘ì€ ê¸ˆì•¡ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        transaction_cost=0.001,
    )

    print(f"í™˜ê²½ ìƒì„± ì™„ë£Œ: {env.n_assets}ê°œ ìì‚°, ìµœëŒ€ {env.max_steps} ìŠ¤í…")

    # 3. í™˜ê²½ reset í…ŒìŠ¤íŠ¸
    print("\n[3] í™˜ê²½ ë¦¬ì…‹ í…ŒìŠ¤íŠ¸...")
    initial_state = env.reset()
    print(f"ì´ˆê¸° ìƒíƒœ í˜•íƒœ: {initial_state.shape}")
    print(f"ì´ˆê¸° ìƒíƒœ ë²”ìœ„: [{initial_state.min():.3f}, {initial_state.max():.3f}]")
    print(f"ìƒíƒœ êµ¬ì„±:")
    print(f"  - ì‹œì¥ íŠ¹ì„±: {initial_state[:12]}")
    print(f"  - ìœ„ê¸° ìˆ˜ì¤€: {initial_state[12]:.4f}")
    print(f"  - ì´ì „ ê°€ì¤‘ì¹˜: {initial_state[13:]}")
    print(f"  - ê°€ì¤‘ì¹˜ í•©: {initial_state[13:].sum():.6f}")

    # 4. 10 ìŠ¤í… ì‹¤í–‰í•˜ì—¬ ë³´ìƒ ì¶”ì 
    print("\n[4] 10 ìŠ¤í… ì‹¤í–‰ í…ŒìŠ¤íŠ¸...")
    rewards = []
    portfolio_values = []
    weight_changes = []

    state = initial_state
    for step in range(10):
        # ëœë¤ ê°€ì¤‘ì¹˜ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
        random_weights = np.random.dirichlet(np.ones(env.n_assets))

        # ìŠ¤í… ì‹¤í–‰
        next_state, reward, done, info = env.step(random_weights)

        rewards.append(reward)
        portfolio_values.append(info["portfolio_value"])
        weight_changes.append(info["weight_change"])

        print(
            f"  ìŠ¤í… {step+1:2d}: ë³´ìƒ={reward:+7.4f}, ê°€ì¹˜={info['portfolio_value']:8.0f}, "
            f"ìˆ˜ìµë¥ ={info['portfolio_return']:+6.2%}, ë¹„ìš©={info['transaction_cost']:6.0f}"
        )

        if done:
            print(f"  ì—í”¼ì†Œë“œ ì¡°ê¸° ì¢…ë£Œ (ìŠ¤í… {step+1})")
            break

        state = next_state

    # 5. ë³´ìƒ ë¶„í¬ ë¶„ì„
    print(f"\n[5] ë³´ìƒ ë¶„í¬ ë¶„ì„...")
    print(f"  í‰ê·  ë³´ìƒ: {np.mean(rewards):+7.4f}")
    print(f"  ë³´ìƒ í‘œì¤€í¸ì°¨: {np.std(rewards):7.4f}")
    print(f"  ë³´ìƒ ë²”ìœ„: [{min(rewards):+6.3f}, {max(rewards):+6.3f}]")
    print(f"  ì œë¡œ ë³´ìƒ ë¹„ìœ¨: {(np.array(rewards) == 0).mean():.1%}")

    # 6. í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ë¶„ì„
    print(f"\n[6] í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼...")
    metrics = env.get_portfolio_metrics()
    print(f"  ìµœì¢… ê°€ì¹˜: {metrics.get('final_value', 0):,.0f}")
    print(f"  ì´ ìˆ˜ìµë¥ : {metrics.get('total_return', 0):+6.2%}")
    print(f"  ë³€ë™ì„±: {metrics.get('volatility', 0):6.2%}")
    print(f"  ìƒ¤í”„ ë¹„ìœ¨: {metrics.get('sharpe_ratio', 0):+6.3f}")
    print(f"  ìµœëŒ€ ë‚™í­: {metrics.get('max_drawdown', 0):6.2%}")

    # 7. ê°€ì¤‘ì¹˜ ê²€ì¦ í†µê³„
    print(f"\n[7] ê°€ì¤‘ì¹˜ ê²€ì¦...")
    print(env.get_validation_summary())

    # 8. íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
    print(f"\n[8] íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸...")

    # 8-1. ê·¹ë‹¨ì  ê°€ì¤‘ì¹˜
    extreme_weights = np.array([1.0, 0.0, 0.0, 0.0, 0.0])
    _, reward_extreme, _, info_extreme = env.step(extreme_weights)
    print(f"  ê·¹ë‹¨ì  ê°€ì¤‘ì¹˜ ë³´ìƒ: {reward_extreme:+7.4f}")

    # 8-2. ìŒìˆ˜ ê°€ì¤‘ì¹˜ (ê²€ì¦ í…ŒìŠ¤íŠ¸)
    negative_weights = np.array([1.5, -0.3, 0.2, 0.3, 0.3])
    _, reward_negative, _, info_negative = env.step(negative_weights)
    print(f"  ìŒìˆ˜ ê°€ì¤‘ì¹˜ ë³´ìƒ: {reward_negative:+7.4f}")

    # 8-3. NaN ê°€ì¤‘ì¹˜
    try:
        nan_weights = np.array([np.nan, 0.25, 0.25, 0.25, 0.25])
        _, reward_nan, _, info_nan = env.step(nan_weights)
        print(f"  NaN ê°€ì¤‘ì¹˜ ë³´ìƒ: {reward_nan:+7.4f}")
    except Exception as e:
        print(f"  NaN ê°€ì¤‘ì¹˜ ì—ëŸ¬: {e}")

    print("\n" + "=" * 80)
    print("í™˜ê²½ ë””ë²„ê¹… ì™„ë£Œ")
    print("=" * 80)

    return {
        "rewards": rewards,
        "portfolio_values": portfolio_values,
        "metrics": metrics,
        "initial_state": initial_state,
    }


def analyze_reward_issues(debug_results):
    """ë³´ìƒ í•¨ìˆ˜ì˜ ë¬¸ì œì  êµ¬ì²´ì  ë¶„ì„"""

    print("\n" + "=" * 60)
    print("ë³´ìƒ í•¨ìˆ˜ ë¬¸ì œì  ë¶„ì„")
    print("=" * 60)

    rewards = debug_results["rewards"]

    # 1. ë³´ìƒ í¬ì†Œì„± (Sparsity) ê²€ì‚¬
    zero_rewards = (np.array(rewards) == 0).sum()
    small_rewards = (np.abs(np.array(rewards)) < 0.001).sum()

    print(f"1. ë³´ìƒ í¬ì†Œì„±:")
    print(
        f"   ì œë¡œ ë³´ìƒ: {zero_rewards}/{len(rewards)} ({zero_rewards/len(rewards):.1%})"
    )
    print(
        f"   ë¯¸ì„¸ ë³´ìƒ: {small_rewards}/{len(rewards)} ({small_rewards/len(rewards):.1%})"
    )

    if zero_rewards > len(rewards) * 0.8:
        print("   âš ï¸  ë³´ìƒì´ ë„ˆë¬´ í¬ì†Œí•©ë‹ˆë‹¤! í•™ìŠµ ì‹ í˜¸ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 2. ë³´ìƒ ë°©í–¥ì„± ê²€ì‚¬
    positive_rewards = (np.array(rewards) > 0).sum()
    negative_rewards = (np.array(rewards) < 0).sum()

    print(f"\n2. ë³´ìƒ ë°©í–¥ì„±:")
    print(
        f"   ì–‘ìˆ˜ ë³´ìƒ: {positive_rewards}/{len(rewards)} ({positive_rewards/len(rewards):.1%})"
    )
    print(
        f"   ìŒìˆ˜ ë³´ìƒ: {negative_rewards}/{len(rewards)} ({negative_rewards/len(rewards):.1%})"
    )

    if abs(positive_rewards - negative_rewards) < len(rewards) * 0.2:
        print("   âœ… ë³´ìƒì´ ê· í˜•ì¡í˜€ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("   âš ï¸  ë³´ìƒì´ í•œìª½ìœ¼ë¡œ í¸í–¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")

    # 3. ë³´ìƒ í¬ê¸° ê²€ì‚¬
    reward_magnitude = np.mean(np.abs(rewards))
    reward_std = np.std(rewards)

    print(f"\n3. ë³´ìƒ í¬ê¸°:")
    print(f"   í‰ê·  ì ˆëŒ€ê°’: {reward_magnitude:.4f}")
    print(f"   í‘œì¤€í¸ì°¨: {reward_std:.4f}")
    print(f"   ì‹ í˜¸ëŒ€ì¡ìŒë¹„: {reward_magnitude/max(reward_std, 1e-8):.2f}")

    if reward_magnitude < 0.01:
        print("   âš ï¸  ë³´ìƒ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤! í•™ìŠµì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    elif reward_magnitude > 1.0:
        print("   âš ï¸  ë³´ìƒ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤! í•™ìŠµì´ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("   âœ… ë³´ìƒ í¬ê¸°ê°€ ì ì ˆí•©ë‹ˆë‹¤.")


if __name__ == "__main__":
    try:
        debug_results = debug_environment()
        analyze_reward_issues(debug_results)

        print(f"\nğŸ¯ í•µì‹¬ ë°œê²¬ì‚¬í•­:")
        print(f"   1. í™˜ê²½ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤")
        print(f"   2. ë³´ìƒ í•¨ìˆ˜ì˜ êµ¬ì²´ì  ë¬¸ì œì ì´ íŒŒì•…ë˜ì—ˆìŠµë‹ˆë‹¤")
        print(f"   3. ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì—ì´ì „íŠ¸ íŒŒë¼ë¯¸í„°ë¥¼ ì ê²€í•´ì•¼ í•©ë‹ˆë‹¤")

    except Exception as e:
        print(f"\nâŒ ë””ë²„ê¹… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
