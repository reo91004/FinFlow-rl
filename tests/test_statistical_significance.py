# tests/test_statistical_significance.py

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
from scipy import stats
from typing import Dict, List, Tuple
from core import ImmunePortfolioBacktester
from constant import *


class StatisticalSignificanceTest:
    """í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.symbols = STOCK_SYMBOLS[:5]  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 5ê°œ ì¢…ëª©ë§Œ
        self.alpha = 0.05  # ìœ ì˜ìˆ˜ì¤€ 5%
        
    def test_vs_buy_and_hold(self, n_runs=10) -> Dict:
        """Buy & Hold ì „ëµ ëŒ€ë¹„ í†µê³„ì  ìœ ì˜ì„± ê²€ì¦"""
        print("=== BIPD vs Buy & Hold í†µê³„ì  ìœ ì˜ì„± í…ŒìŠ¤íŠ¸ ===")
        
        bipd_sharpes = []
        buyhold_sharpes = []
        bipd_returns = []
        buyhold_returns = []
        
        for run in range(n_runs):
            print(f"  ì‹¤í–‰ {run + 1}/{n_runs}")
            
            # ë°±í…ŒìŠ¤í„° ì´ˆê¸°í™”
            backtester = ImmunePortfolioBacktester(
                self.symbols, TRAIN_START_DATE, TRAIN_END_DATE,
                TEST_START_DATE, TEST_END_DATE
            )
            
            try:
                # BIPD ì„±ê³¼
                bipd_portfolio_returns, _ = backtester.backtest_single_run(
                    seed=42 + run,
                    return_model=False,
                    use_learning_bcells=True,
                    use_hierarchical=True,
                    use_curriculum=False,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
                    logging_level="minimal"
                )
                
                bipd_metrics = backtester.calculate_metrics(bipd_portfolio_returns)
                bipd_sharpes.append(bipd_metrics['Sharpe Ratio'])
                bipd_returns.append(bipd_metrics['Total Return'])
                
                # Buy & Hold ê¸°ì¤€ì„ 
                baseline_returns = backtester.calculate_baseline_performance()
                baseline_metrics = backtester.calculate_metrics(baseline_returns)
                buyhold_sharpes.append(baseline_metrics['Sharpe Ratio'])
                buyhold_returns.append(baseline_metrics['Total Return'])
                
            except Exception as e:
                print(f"    ì‹¤í–‰ {run + 1} ì‹¤íŒ¨: {e}")
                continue
        
        return self._analyze_statistical_significance(
            bipd_sharpes, buyhold_sharpes, bipd_returns, buyhold_returns
        )
    
    def _analyze_statistical_significance(
        self, bipd_sharpes: List[float], buyhold_sharpes: List[float],
        bipd_returns: List[float], buyhold_returns: List[float]
    ) -> Dict:
        """í†µê³„ì  ìœ ì˜ì„± ë¶„ì„"""
        
        results = {
            'sample_size': min(len(bipd_sharpes), len(buyhold_sharpes)),
            'alpha': self.alpha
        }
        
        if results['sample_size'] < 3:
            results['error'] = "ì¶©ë¶„í•œ ìƒ˜í”Œ ìˆ˜ ì—†ìŒ"
            return results
        
        # ìƒ¤í”„ ë¹„ìœ¨ ë¹„êµ
        sharpe_t_stat, sharpe_p_value = stats.ttest_rel(bipd_sharpes, buyhold_sharpes)
        
        results['sharpe_ratio'] = {
            'bipd_mean': np.mean(bipd_sharpes),
            'bipd_std': np.std(bipd_sharpes),
            'buyhold_mean': np.mean(buyhold_sharpes),
            'buyhold_std': np.std(buyhold_sharpes),
            'improvement': np.mean(bipd_sharpes) - np.mean(buyhold_sharpes),
            't_statistic': sharpe_t_stat,
            'p_value': sharpe_p_value,
            'is_significant': sharpe_p_value < self.alpha,
            'effect_size': self._calculate_cohens_d(bipd_sharpes, buyhold_sharpes)
        }
        
        # ì´ ìˆ˜ìµë¥  ë¹„êµ
        return_t_stat, return_p_value = stats.ttest_rel(bipd_returns, buyhold_returns)
        
        results['total_return'] = {
            'bipd_mean': np.mean(bipd_returns),
            'bipd_std': np.std(bipd_returns),
            'buyhold_mean': np.mean(buyhold_returns),
            'buyhold_std': np.std(buyhold_returns),
            'improvement': np.mean(bipd_returns) - np.mean(buyhold_returns),
            't_statistic': return_t_stat,
            'p_value': return_p_value,
            'is_significant': return_p_value < self.alpha,
            'effect_size': self._calculate_cohens_d(bipd_returns, buyhold_returns)
        }
        
        return results
    
    def _calculate_cohens_d(self, group1: List[float], group2: List[float]) -> float:
        """Cohen's d (íš¨ê³¼ í¬ê¸°) ê³„ì‚°"""
        n1, n2 = len(group1), len(group2)
        s1, s2 = np.std(group1, ddof=1), np.std(group2, ddof=1)
        
        # í•©ë™ í‘œì¤€í¸ì°¨
        pooled_std = np.sqrt(((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / (n1 + n2 - 2))
        
        # Cohen's d
        return (np.mean(group1) - np.mean(group2)) / pooled_std
    
    def test_system_stability(self, n_runs=15) -> Dict:
        """ì‹œìŠ¤í…œ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸"""
        print("=== ì‹œìŠ¤í…œ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ===")
        
        sharpe_ratios = []
        success_count = 0
        failure_count = 0
        
        target_sharpe = 0.5  # ëª©í‘œ ìƒ¤í”„ ë¹„ìœ¨
        
        for run in range(n_runs):
            print(f"  ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ {run + 1}/{n_runs}")
            
            backtester = ImmunePortfolioBacktester(
                self.symbols, TRAIN_START_DATE, TRAIN_END_DATE,
                TEST_START_DATE, TEST_END_DATE
            )
            
            try:
                portfolio_returns, _ = backtester.backtest_single_run(
                    seed=100 + run,
                    return_model=False,
                    use_learning_bcells=True,
                    use_hierarchical=True,
                    use_curriculum=False,
                    logging_level="minimal"
                )
                
                metrics = backtester.calculate_metrics(portfolio_returns)
                sharpe = metrics['Sharpe Ratio']
                sharpe_ratios.append(sharpe)
                
                if sharpe >= target_sharpe:
                    success_count += 1
                else:
                    failure_count += 1
                    
            except Exception as e:
                print(f"    ì‹¤í–‰ {run + 1} ì‹¤íŒ¨: {e}")
                failure_count += 1
                sharpe_ratios.append(0.0)  # ì‹¤íŒ¨í•œ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬
        
        # ì•ˆì •ì„± ë©”íŠ¸ë¦­ ê³„ì‚°
        success_rate = success_count / n_runs
        sharpe_mean = np.mean(sharpe_ratios)
        sharpe_std = np.std(sharpe_ratios)
        coefficient_of_variation = sharpe_std / sharpe_mean if sharpe_mean != 0 else float('inf')
        
        return {
            'total_runs': n_runs,
            'success_count': success_count,
            'failure_count': failure_count,
            'success_rate': success_rate,
            'target_sharpe': target_sharpe,
            'sharpe_statistics': {
                'mean': sharpe_mean,
                'std': sharpe_std,
                'min': np.min(sharpe_ratios),
                'max': np.max(sharpe_ratios),
                'median': np.median(sharpe_ratios),
                'coefficient_of_variation': coefficient_of_variation
            },
            'is_stable': success_rate >= 0.7 and coefficient_of_variation <= 0.5
        }
    
    def run_comprehensive_validation(self) -> Dict:
        """ì¢…í•© ê²€ì¦ ì‹¤í–‰"""
        print("=== BIPD ì‹œìŠ¤í…œ ì¢…í•© ê²€ì¦ ===\n")
        
        # 1. í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
        significance_results = self.test_vs_buy_and_hold(n_runs=8)
        
        # 2. ì‹œìŠ¤í…œ ì•ˆì •ì„± ê²€ì¦
        stability_results = self.test_system_stability(n_runs=10)
        
        # 3. ì¢…í•© í‰ê°€
        overall_score = self._calculate_overall_score(significance_results, stability_results)
        
        return {
            'significance_test': significance_results,
            'stability_test': stability_results,
            'overall_assessment': overall_score
        }
    
    def _calculate_overall_score(self, significance: Dict, stability: Dict) -> Dict:
        """ì¢…í•© í‰ê°€ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        max_score = 100
        
        # í†µê³„ì  ìœ ì˜ì„± ì ìˆ˜ (50ì  ë§Œì )
        if not significance.get('error'):
            if significance['sharpe_ratio']['is_significant']:
                score += 30
            if significance['total_return']['is_significant']:
                score += 20
        
        # ì‹œìŠ¤í…œ ì•ˆì •ì„± ì ìˆ˜ (50ì  ë§Œì )
        if stability['is_stable']:
            score += 30
        if stability['success_rate'] >= 0.6:
            score += 20
        
        grade = 'A' if score >= 80 else 'B' if score >= 60 else 'C' if score >= 40 else 'D'
        
        return {
            'score': score,
            'max_score': max_score,
            'percentage': score / max_score,
            'grade': grade,
            'passed': score >= 60
        }


def main():
    """í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ ì‹¤í–‰"""
    test_suite = StatisticalSignificanceTest()
    
    try:
        results = test_suite.run_comprehensive_validation()
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ“Š ì¢…í•© ê²€ì¦ ê²°ê³¼")
        print("="*60)
        
        # í†µê³„ì  ìœ ì˜ì„± ê²°ê³¼
        sig = results['significance_test']
        if not sig.get('error'):
            print(f"\nğŸ”¬ í†µê³„ì  ìœ ì˜ì„± (ìƒ˜í”Œ ìˆ˜: {sig['sample_size']})")
            
            sharpe = sig['sharpe_ratio']
            print(f"  ìƒ¤í”„ ë¹„ìœ¨:")
            print(f"    BIPD: {sharpe['bipd_mean']:.3f} Â± {sharpe['bipd_std']:.3f}")
            print(f"    Buy&Hold: {sharpe['buyhold_mean']:.3f} Â± {sharpe['buyhold_std']:.3f}")
            print(f"    ê°œì„ ë„: {sharpe['improvement']:.3f}")
            print(f"    p-value: {sharpe['p_value']:.4f} ({'âœ… ìœ ì˜í•¨' if sharpe['is_significant'] else 'âŒ ìœ ì˜í•˜ì§€ ì•ŠìŒ'})")
            print(f"    íš¨ê³¼ í¬ê¸°: {sharpe['effect_size']:.3f}")
            
            ret = sig['total_return']
            print(f"  ì´ ìˆ˜ìµë¥ :")
            print(f"    BIPD: {ret['bipd_mean']:.2%} Â± {ret['bipd_std']:.2%}")
            print(f"    Buy&Hold: {ret['buyhold_mean']:.2%} Â± {ret['buyhold_std']:.2%}")
            print(f"    ê°œì„ ë„: {ret['improvement']:.2%}")
            print(f"    p-value: {ret['p_value']:.4f} ({'âœ… ìœ ì˜í•¨' if ret['is_significant'] else 'âŒ ìœ ì˜í•˜ì§€ ì•ŠìŒ'})")
            
        # ì•ˆì •ì„± ê²°ê³¼
        stab = results['stability_test']
        print(f"\nâš–ï¸ ì‹œìŠ¤í…œ ì•ˆì •ì„±")
        print(f"  ì„±ê³µë¥ : {stab['success_rate']:.1%} ({stab['success_count']}/{stab['total_runs']})")
        print(f"  í‰ê·  ìƒ¤í”„ ë¹„ìœ¨: {stab['sharpe_statistics']['mean']:.3f}")
        print(f"  ë³€ë™ ê³„ìˆ˜: {stab['sharpe_statistics']['coefficient_of_variation']:.3f}")
        print(f"  ì•ˆì •ì„±: {'âœ… ì•ˆì •í•¨' if stab['is_stable'] else 'âŒ ë¶ˆì•ˆì •í•¨'}")
        
        # ì¢…í•© í‰ê°€
        overall = results['overall_assessment']
        print(f"\nğŸ† ì¢…í•© í‰ê°€")
        print(f"  ì ìˆ˜: {overall['score']}/{overall['max_score']} ({overall['percentage']:.1%})")
        print(f"  ë“±ê¸‰: {overall['grade']}")
        print(f"  í•©ê²©: {'âœ… PASS' if overall['passed'] else 'âŒ FAIL'}")
        
        return overall['passed']
        
    except Exception as e:
        print(f"\nâŒ ê²€ì¦ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ BIPD ì‹œìŠ¤í…œì´ í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâš ï¸ BIPD ì‹œìŠ¤í…œì´ ì¼ë¶€ ê²€ì¦ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("   ë” ë§ì€ ë°ì´í„°ë‚˜ íŒŒë¼ë¯¸í„° ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")