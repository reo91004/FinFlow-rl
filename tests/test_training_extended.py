# tests/debug_training_extended.py - ì¶©ë¶„í•œ ê²½í—˜ìœ¼ë¡œ í•™ìŠµ ì‹ í˜¸ ì¬ë¶„ì„

import os
import sys
import warnings

warnings.filterwarnings("ignore")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import torch
import pandas as pd
from datetime import datetime

from config import *
from agents.bcell import BCell
from data import DataLoader
from core.environment import PortfolioEnvironment
from core.system import ImmunePortfolioSystem
from data.features import FeatureExtractor


def debug_training_with_sufficient_data():
    """ì¶©ë¶„í•œ ë°ì´í„°ë¡œ í•™ìŠµ ì‹ í˜¸ ë””ë²„ê¹…"""

    print("=" * 80)
    print("í™•ì¥ëœ í•™ìŠµ ì‹ í˜¸ ë””ë²„ê¹… (ì¶©ë¶„í•œ ê²½í—˜)")
    print("=" * 80)

    # 1. ë” í° í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì„±
    print("[1] í™•ì¥ëœ í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì„±...")

    # ë” í° ë°ì´í„°ì…‹ ìƒì„± (100 ê±°ë˜ì¼)
    dates = pd.date_range("2020-01-01", periods=100, freq="D")
    symbols = SYMBOLS[:5]
    np.random.seed(42)
    returns = np.random.normal(0.001, 0.02, (100, 5))
    prices = pd.DataFrame(
        np.cumprod(1 + returns, axis=0) * 100, index=dates, columns=symbols
    )

    # í™˜ê²½ ë° ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    feature_extractor = FeatureExtractor(lookback_window=20)
    env = PortfolioEnvironment(prices, feature_extractor, initial_capital=100000)
    immune_system = ImmunePortfolioSystem(n_assets=len(symbols), state_dim=18)

    # ë”ë¯¸ í•™ìŠµ ë°ì´í„°ë¡œ T-Cell í›ˆë ¨
    dummy_features = np.random.randn(200, 12)
    immune_system.fit_tcell(dummy_features)

    print(f"í™˜ê²½ ì„¤ì • ì™„ë£Œ: {len(symbols)}ê°œ ìì‚°, {env.max_steps} ìŠ¤í…")

    # 2. ì¶©ë¶„í•œ ê²½í—˜ ìˆ˜ì§‘ (75 ìŠ¤í… - ë°°ì¹˜ í¬ê¸°ë³´ë‹¤ ë§ì´)
    print(f"\n[2] ì¶©ë¶„í•œ ê²½í—˜ ìˆ˜ì§‘ (75 ìŠ¤í…)...")

    state = env.reset()
    total_reward = 0
    bcell_usage = {}

    for step in range(75):
        # ì˜ì‚¬ê²°ì •
        weights, decision_info = immune_system.decide(state, training=True)

        # í™˜ê²½ ìŠ¤í…
        next_state, reward, done, info = env.step(weights)
        total_reward += reward

        # B-Cell ì‚¬ìš© í†µê³„
        selected = decision_info["selected_bcell"]
        bcell_usage[selected] = bcell_usage.get(selected, 0) + 1

        # ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ (ê²½í—˜ ì €ì¥)
        immune_system.update(state, weights, reward, next_state, done)

        if step % 15 == 0:
            print(
                f"  ìŠ¤í… {step+1:2d}: ë³´ìƒ={reward:+7.4f}, ëˆ„ì ë³´ìƒ={total_reward:+8.4f}, ì„ íƒ={selected[:4]}"
            )

        state = next_state
        if done:
            print(f"  ì—í”¼ì†Œë“œ ì¡°ê¸° ì¢…ë£Œ (ìŠ¤í… {step+1})")
            break

    print(f"\nê²½í—˜ ìˆ˜ì§‘ ì™„ë£Œ:")
    print(f"  ì´ ìŠ¤í…: {step+1}")
    print(f"  ëˆ„ì  ë³´ìƒ: {total_reward:+8.4f}")
    print(f"  í‰ê·  ë³´ìƒ: {total_reward/(step+1):+7.4f}")
    print(f"  B-Cell ì‚¬ìš© ë¶„í¬: {bcell_usage}")

    # 3. ê° B-Cellì˜ ë²„í¼ í¬ê¸° í™•ì¸
    print(f"\n[3] B-Cell ë²„í¼ ìƒíƒœ í™•ì¸...")

    active_bcells = []
    for bcell_name, bcell in immune_system.bcells.items():
        buffer_size = len(bcell.replay_buffer)
        print(f"  {bcell_name:10s}: {buffer_size:3d}/64 ê²½í—˜ ë³´ìœ ")

        if buffer_size >= bcell.batch_size:
            active_bcells.append((bcell_name, bcell))
            print(f"    âœ… í•™ìŠµ ê°€ëŠ¥")
        else:
            print(f"    âš ï¸  ê²½í—˜ ë¶€ì¡±")

    print(f"\ní•™ìŠµ ê°€ëŠ¥í•œ B-Cell: {len(active_bcells)}ê°œ")

    # 4. í•™ìŠµ ê°€ëŠ¥í•œ B-Cellë“¤ì˜ í•™ìŠµ ì‹ í˜¸ ë¶„ì„
    print(f"\n[4] í•™ìŠµ ì‹ í˜¸ ìƒì„¸ ë¶„ì„...")

    training_results = {}

    for bcell_name, bcell in active_bcells:
        print(f"\n  === {bcell_name} B-Cell í•™ìŠµ ì‹ í˜¸ ===")

        # í•™ìŠµ ì „ ì†ì‹¤ ê¸°ë¡
        initial_actor_losses = len(bcell.actor_losses)
        initial_critic_losses = len(bcell.critic_losses)
        initial_alpha = bcell.alpha.item()

        print(f"    í•™ìŠµ ì „ ìƒíƒœ:")
        print(f"      Alpha: {initial_alpha:.4f}")
        print(f"      ì—…ë°ì´íŠ¸ íšŸìˆ˜: {bcell.update_count}")
        print(f"      ë²„í¼ í¬ê¸°: {len(bcell.replay_buffer)}")

        # 10íšŒ ì—°ì† ì—…ë°ì´íŠ¸
        print(f"    10íšŒ ì—…ë°ì´íŠ¸ ì‹¤í–‰ì¤‘...")

        actor_losses = []
        critic_losses = []
        alpha_values = []

        for update_i in range(10):
            # ì†ì‹¤ ê¸°ë¡ì„ ìœ„í•œ ì—…ë°ì´íŠ¸ ì „ ê°’
            pre_actor_count = len(bcell.actor_losses)
            pre_critic_count = len(bcell.critic_losses)
            pre_alpha = bcell.alpha.item()

            # ì—…ë°ì´íŠ¸ ì‹¤í–‰
            bcell.update()

            # ì†ì‹¤ ê°’ ìˆ˜ì§‘
            if len(bcell.actor_losses) > pre_actor_count:
                actor_losses.append(bcell.actor_losses[-1])
            if len(bcell.critic_losses) > pre_critic_count:
                critic_losses.append(bcell.critic_losses[-1])

            alpha_values.append(bcell.alpha.item())

        # í•™ìŠµ í›„ ë¶„ì„
        if actor_losses and critic_losses:
            avg_actor_loss = np.mean(actor_losses)
            avg_critic_loss = np.mean(critic_losses)
            final_alpha = bcell.alpha.item()
            alpha_change = final_alpha - initial_alpha

            print(f"    í•™ìŠµ í›„ ë¶„ì„:")
            print(f"      í‰ê·  Actor Loss: {avg_actor_loss:.6f}")
            print(f"      í‰ê·  Critic Loss: {avg_critic_loss:.6f}")
            print(f"      ìµœì¢… Alpha: {final_alpha:.4f} (ë³€í™”: {alpha_change:+.4f})")
            print(f"      ì´ ì—…ë°ì´íŠ¸: {bcell.update_count}")

            # ì†ì‹¤ ì•ˆì •ì„± ì²´í¬
            actor_loss_std = np.std(actor_losses) if len(actor_losses) > 1 else 0
            critic_loss_std = np.std(critic_losses) if len(critic_losses) > 1 else 0

            print(f"      Actor Loss ë³€ë™: {actor_loss_std:.6f}")
            print(f"      Critic Loss ë³€ë™: {critic_loss_std:.6f}")

            # ë¬¸ì œ ì§„ë‹¨
            issues = []
            if np.isnan(avg_actor_loss) or np.isnan(avg_critic_loss):
                issues.append("NaN ì†ì‹¤ ë°œìƒ")
            if avg_actor_loss > 1000:
                issues.append("Actor ì†ì‹¤ ê³¼ë„í•¨")
            if avg_critic_loss > 1000:
                issues.append("Critic ì†ì‹¤ ê³¼ë„í•¨")
            if actor_loss_std > avg_actor_loss:
                issues.append("Actor ì†ì‹¤ ë¶ˆì•ˆì •")
            if critic_loss_std > avg_critic_loss:
                issues.append("Critic ì†ì‹¤ ë¶ˆì•ˆì •")
            if abs(alpha_change) < 1e-4:
                issues.append("Alpha í•™ìŠµ ì •ì²´")

            if issues:
                print(f"      âš ï¸  ë°œê²¬ëœ ë¬¸ì œ:")
                for issue in issues:
                    print(f"        - {issue}")
            else:
                print(f"      âœ… í•™ìŠµ ì‹ í˜¸ ì–‘í˜¸")

            training_results[bcell_name] = {
                "avg_actor_loss": avg_actor_loss,
                "avg_critic_loss": avg_critic_loss,
                "final_alpha": final_alpha,
                "alpha_change": alpha_change,
                "actor_loss_std": actor_loss_std,
                "critic_loss_std": critic_loss_std,
                "issues": issues,
            }
        else:
            print(f"      âš ï¸  ì†ì‹¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")

    # 5. ì¢…í•© ì§„ë‹¨
    print(f"\n[5] ì¢…í•© ì§„ë‹¨...")

    total_issues = []
    healthy_bcells = 0

    for bcell_name, results in training_results.items():
        if not results["issues"]:
            healthy_bcells += 1
        else:
            total_issues.extend(
                [f"{bcell_name}: {issue}" for issue in results["issues"]]
            )

    print(f"  ì •ìƒ B-Cell: {healthy_bcells}/{len(training_results)}")
    print(f"  ì´ ë¬¸ì œì : {len(total_issues)}ê°œ")

    if total_issues:
        print(f"  ë°œê²¬ëœ ë¬¸ì œì ë“¤:")
        for i, issue in enumerate(total_issues[:10], 1):  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
            print(f"    {i}. {issue}")
        if len(total_issues) > 10:
            print(f"    ... ì™¸ {len(total_issues)-10}ê°œ")
    else:
        print(f"  âœ… ëª¨ë“  B-Cellì´ ì •ìƒì ìœ¼ë¡œ í•™ìŠµ ì¤‘")

    print("\n" + "=" * 80)
    print("í™•ì¥ëœ í•™ìŠµ ì‹ í˜¸ ë””ë²„ê¹… ì™„ë£Œ")
    print("=" * 80)

    return {
        "training_results": training_results,
        "total_issues": total_issues,
        "bcell_usage": bcell_usage,
        "total_reward": total_reward,
        "steps_completed": step + 1,
    }


def recommend_improvements(debug_results):
    """êµ¬ì²´ì  ê°œì„  ë°©ì•ˆ ì œì•ˆ"""

    print("\n" + "=" * 60)
    print("êµ¬ì²´ì  ê°œì„  ë°©ì•ˆ")
    print("=" * 60)

    training_results = debug_results["training_results"]
    total_issues = debug_results["total_issues"]

    recommendations = []

    # 1. ê²½í—˜ ë¶€ì¡± ë¬¸ì œ
    if len(training_results) < 3:
        recommendations.append(
            {
                "category": "ë°ì´í„° ìˆ˜ì§‘",
                "issue": "ì¶©ë¶„í•œ ê²½í—˜ ë¶€ì¡±",
                "solution": "ì´ˆê¸° ì—í”¼ì†Œë“œ ê¸¸ì´ ì¦ê°€ (252 â†’ 500 ìŠ¤í…)",
                "priority": "HIGH",
            }
        )

    # 2. ì†ì‹¤ ê´€ë ¨ ë¬¸ì œ
    nan_issues = [issue for issue in total_issues if "NaN" in issue]
    if nan_issues:
        recommendations.append(
            {
                "category": "ìˆ˜ì¹˜ ì•ˆì •ì„±",
                "issue": "NaN ì†ì‹¤ ë°œìƒ",
                "solution": "Gradient clipping ê°•í™”, í•™ìŠµë¥  ê°ì†Œ (1e-4 â†’ 5e-5)",
                "priority": "CRITICAL",
            }
        )

    # 3. ë¶ˆì•ˆì •ì„± ë¬¸ì œ
    unstable_issues = [issue for issue in total_issues if "ë¶ˆì•ˆì •" in issue]
    if unstable_issues:
        recommendations.append(
            {
                "category": "í•™ìŠµ ì•ˆì •ì„±",
                "issue": "ì†ì‹¤ ë¶ˆì•ˆì •",
                "solution": "Target network ì—…ë°ì´íŠ¸ ë¹ˆë„ ê°ì†Œ (TAU: 0.005 â†’ 0.001)",
                "priority": "MEDIUM",
            }
        )

    # 4. Alpha í•™ìŠµ ì •ì²´
    alpha_issues = [issue for issue in total_issues if "Alpha" in issue]
    if alpha_issues:
        recommendations.append(
            {
                "category": "íƒí—˜ ì „ëµ",
                "issue": "Alpha ìë™ ì¡°ì • ì •ì²´",
                "solution": "Alpha í•™ìŠµë¥  ì¦ê°€ (1e-4 â†’ 3e-4), Target entropy ì¡°ì •",
                "priority": "MEDIUM",
            }
        )

    # 5. ë³´ìƒ ë¬¸ì œ
    avg_reward = debug_results["total_reward"] / debug_results["steps_completed"]
    if abs(avg_reward) < 1e-4:
        recommendations.append(
            {
                "category": "ë³´ìƒ í•¨ìˆ˜",
                "issue": "ë³´ìƒ ì‹ í˜¸ ë¯¸ì•½",
                "solution": "ë³´ìƒ ìŠ¤ì¼€ì¼ë§, Sharpe window ê°ì†Œ (20 â†’ 10)",
                "priority": "HIGH",
            }
        )

    # ì¶œë ¥
    if recommendations:
        print(f"ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ë°©ì•ˆ:")

        for priority in ["CRITICAL", "HIGH", "MEDIUM"]:
            priority_recs = [r for r in recommendations if r["priority"] == priority]
            if priority_recs:
                print(f"\n{priority} ìš°ì„ ìˆœìœ„:")
                for i, rec in enumerate(priority_recs, 1):
                    print(f"  {i}. [{rec['category']}] {rec['issue']}")
                    print(f"     í•´ê²°ì±…: {rec['solution']}")
    else:
        print("âœ… ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # êµ¬ì²´ì  ì„¤ì •ê°’ ì œì•ˆ
    print(f"\nê¶Œì¥ ì„¤ì •ê°’ ë³€ê²½:")
    print(f"  config.py ìˆ˜ì •:")
    print(f"    LR_ACTOR = 3e-4  # í˜„ì¬: {LR_ACTOR}")
    print(f"    LR_CRITIC = 3e-4  # í˜„ì¬: {LR_CRITIC}")
    print(f"    ALPHA_LR = 3e-4  # í˜„ì¬: {ALPHA_LR}")
    print(f"    TAU = 0.001  # í˜„ì¬: {TAU}")
    print(f"    BATCH_SIZE = 32  # í˜„ì¬: {BATCH_SIZE} (ë” ë¹ ë¥¸ ì—…ë°ì´íŠ¸)")

    if avg_reward < 1e-4:
        print(f"  environment.py ìˆ˜ì •:")
        print(f"    sharpe_window = 10  # í˜„ì¬: 20")
        print(f"    ë³´ìƒ ìŠ¤ì¼€ì¼ë§ ì¶”ê°€")


if __name__ == "__main__":
    try:
        debug_results = debug_training_with_sufficient_data()
        recommend_improvements(debug_results)

        print(f"\nğŸ¯ í•µì‹¬ ë°œê²¬ì‚¬í•­:")
        print(f"   1. ë°°ì¹˜ í¬ê¸° vs ê²½í—˜ ë¶€ì¡± ë¬¸ì œ í•´ê²°ë¨")
        print(f"   2. ì‹¤ì œ í•™ìŠµ ì‹ í˜¸ ë¶„ì„ ì™„ë£Œ")
        print(f"   3. êµ¬ì²´ì  ê°œì„  ë°©ì•ˆ ë„ì¶œë¨")

    except Exception as e:
        print(f"\nâŒ í™•ì¥ëœ í•™ìŠµ ë””ë²„ê¹… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
