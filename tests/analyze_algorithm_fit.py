# tests/analyze_algorithm_fit.py - SACì™€ í¬íŠ¸í´ë¦¬ì˜¤ í™˜ê²½ì˜ ì í•©ì„± ë¶„ì„

import os
import sys
import warnings

warnings.filterwarnings("ignore")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd

from config import *


def analyze_sac_portfolio_fit():
    """SAC ì•Œê³ ë¦¬ì¦˜ê³¼ í¬íŠ¸í´ë¦¬ì˜¤ í™˜ê²½ì˜ ì í•©ì„± ë¶„ì„"""

    print("=" * 80)
    print("SAC-í¬íŠ¸í´ë¦¬ì˜¤ ì í•©ì„± ë¶„ì„")
    print("=" * 80)

    analysis = {
        "environment_characteristics": {},
        "sac_strengths": {},
        "potential_mismatches": {},
        "recommendations": {},
    }

    # 1. í™˜ê²½ íŠ¹ì„± ë¶„ì„
    print("[1] í¬íŠ¸í´ë¦¬ì˜¤ í™˜ê²½ íŠ¹ì„± ë¶„ì„...")

    env_chars = {
        "action_space": "Continuous (Simplex constraint)",
        "state_space": f"High-dimensional ({12 + 1 + len(SYMBOLS)}D)",
        "reward_structure": "Dense but noisy",
        "episode_length": f"{MAX_STEPS} steps",
        "stochasticity": "High (market volatility)",
        "partial_observability": "Medium (limited market info)",
        "multi_objective": "Yes (return vs risk vs concentration)",
    }

    for key, value in env_chars.items():
        print(f"  {key.replace('_', ' ').title()}: {value}")

    analysis["environment_characteristics"] = env_chars

    # 2. SAC ì•Œê³ ë¦¬ì¦˜ ê°•ì  ë¶„ì„
    print(f"\n[2] SAC ì•Œê³ ë¦¬ì¦˜ ê°•ì  ë¶„ì„...")

    sac_strengths = {
        "continuous_actions": "âœ… í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ì— ìµœì ",
        "sample_efficiency": "âœ… ì˜¤í”„í´ë¦¬ì‹œ í•™ìŠµìœ¼ë¡œ íš¨ìœ¨ì ",
        "exploration": "âœ… ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ìë™ íƒí—˜",
        "stability": "âœ… Twin Q-networksë¡œ ê³¼ì¶”ì • ë°©ì§€",
        "stochastic_policy": "âœ… ì‹œì¥ ë¶ˆí™•ì‹¤ì„±ì— ì í•©",
        "automatic_tuning": "âœ… Alpha ìë™ ì¡°ì •",
    }

    for strength, desc in sac_strengths.items():
        print(f"  {strength.replace('_', ' ').title()}: {desc}")

    analysis["sac_strengths"] = sac_strengths

    # 3. ì ì¬ì  ë¶€ì í•© ìš”ì†Œ ë¶„ì„
    print(f"\n[3] ì ì¬ì  ë¶€ì í•© ìš”ì†Œ ë¶„ì„...")

    potential_issues = []

    # 3-1. Simplex ì œì•½ ë¬¸ì œ
    print(f"  [3-1] Simplex ì œì•½ ë¶„ì„:")
    simplex_issue = {
        "problem": "Dirichlet ë¶„í¬ vs ì‹¤ì œ ì œì•½ ë¶ˆì¼ì¹˜",
        "description": "DirichletëŠ” ìì—°ìŠ¤ëŸ¬ìš´ simplexì´ì§€ë§Œ min/max ì œì•½ (0.001~0.8) ì¡´ì¬",
        "severity": "MEDIUM",
        "evidence": "ê°€ì¤‘ì¹˜ ê²€ì¦ì—ì„œ clipping ë°œìƒ",
    }
    print(f"    ë¬¸ì œ: {simplex_issue['problem']}")
    print(f"    ì„¤ëª…: {simplex_issue['description']}")
    print(f"    ì‹¬ê°ë„: {simplex_issue['severity']}")

    potential_issues.append(simplex_issue)

    # 3-2. ë‹¤ëª©ì  ìµœì í™” ë¬¸ì œ
    print(f"  [3-2] ë‹¤ëª©ì  ìµœì í™” ë¶„ì„:")
    multi_obj_issue = {
        "problem": "ë³µí•© ë³´ìƒ í•¨ìˆ˜ë¡œ ì¸í•œ ì‹ í˜¸ í˜¼ì¬",
        "description": "base_reward + sharpe_reward - concentration_penalty",
        "severity": "HIGH",
        "evidence": "ë³´ìƒ í¸í–¥ì„± (60% ì–‘ìˆ˜ vs 40% ìŒìˆ˜)",
    }
    print(f"    ë¬¸ì œ: {multi_obj_issue['problem']}")
    print(f"    ì„¤ëª…: {multi_obj_issue['description']}")
    print(f"    ì‹¬ê°ë„: {multi_obj_issue['severity']}")

    potential_issues.append(multi_obj_issue)

    # 3-3. ê³ ì°¨ì› ìƒíƒœê³µê°„ ë¬¸ì œ
    print(f"  [3-3] ê³ ì°¨ì› ìƒíƒœê³µê°„ ë¶„ì„:")
    high_dim_issue = {
        "problem": f"{12 + 1 + len(SYMBOLS)}ì°¨ì› ìƒíƒœê³µê°„",
        "description": "ì‹œì¥íŠ¹ì„±(12) + ìœ„ê¸°(1) + ê°€ì¤‘ì¹˜(30) = 43ì°¨ì›",
        "severity": "MEDIUM",
        "evidence": "ì´ˆê¸° ì •ê·œí™” ì´ìŠˆ, í•™ìŠµ ì´ˆê¸° ë¶ˆì•ˆì •ì„±",
    }
    print(f"    ë¬¸ì œ: {high_dim_issue['problem']}")
    print(f"    ì„¤ëª…: {high_dim_issue['description']}")
    print(f"    ì‹¬ê°ë„: {high_dim_issue['severity']}")

    potential_issues.append(high_dim_issue)

    # 3-4. íƒí—˜-í™œìš© ê· í˜• ë¬¸ì œ
    print(f"  [3-4] íƒí—˜-í™œìš© ê· í˜• ë¶„ì„:")
    exploration_issue = {
        "problem": "Target entropyê°€ íƒí—˜ì„ ê³¼ë„í•˜ê²Œ ì–µì œ",
        "description": f"Target entropy = -2.5 (action_dim * 0.5)ê°€ ë„ˆë¬´ ë‚®ìŒ",
        "severity": "HIGH",
        "evidence": "íƒí—˜ ë¹„ìœ¨ 0.87 < 1.5 (ê¶Œì¥)",
    }
    print(f"    ë¬¸ì œ: {exploration_issue['problem']}")
    print(f"    ì„¤ëª…: {exploration_issue['description']}")
    print(f"    ì‹¬ê°ë„: {exploration_issue['severity']}")

    potential_issues.append(exploration_issue)

    analysis["potential_mismatches"] = potential_issues

    # 4. ëŒ€ì•ˆ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ
    print(f"\n[4] ëŒ€ì•ˆ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ë¶„ì„...")

    alternatives = {
        "PPO": {
            "pros": ["ì•ˆì •ì ", "êµ¬í˜„ ë‹¨ìˆœ", "ì •ì±… ì œì•½ ê°€ëŠ¥"],
            "cons": ["ìƒ˜í”Œ íš¨ìœ¨ì„± ë‚®ìŒ", "simplex ì œì•½ ì–´ë ¤ì›€"],
            "fit_score": 7,
        },
        "DDPG": {
            "pros": ["ì—°ì† í–‰ë™", "ìƒ˜í”Œ íš¨ìœ¨ì„±"],
            "cons": ["ê²°ì •ì  ì •ì±…", "íƒí—˜ ì–´ë ¤ì›€", "ê³¼ì¶”ì •"],
            "fit_score": 6,
        },
        "TD3": {
            "pros": ["DDPG ê°œì„ ", "Twin critics"],
            "cons": ["ì—¬ì „íˆ ê²°ì •ì ", "simplex ì œì•½ ì–´ë ¤ì›€"],
            "fit_score": 7,
        },
        "SAC": {
            "pros": ["í™•ë¥ ì  ì •ì±…", "ìë™ íƒí—˜", "simplex ì í•©"],
            "cons": ["ë³µí•© ë³´ìƒ ë¯¼ê°", "í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê°"],
            "fit_score": 8,
        },
    }

    print(f"  ì•Œê³ ë¦¬ì¦˜ ì í•©ë„ ì ìˆ˜ (10ì  ë§Œì ):")
    for alg, details in alternatives.items():
        print(f"    {alg}: {details['fit_score']}/10")
        print(f"      ì¥ì : {', '.join(details['pros'])}")
        print(f"      ë‹¨ì : {', '.join(details['cons'])}")

    best_algorithm = max(
        alternatives.keys(), key=lambda k: alternatives[k]["fit_score"]
    )
    print(
        f"\n  ê²°ë¡ : {best_algorithm}ì´ ê°€ì¥ ì í•© ({alternatives[best_algorithm]['fit_score']}/10)"
    )

    # 5. êµ¬ì²´ì  ê°œì„  ê¶Œì¥ì‚¬í•­
    print(f"\n[5] SAC ìµœì í™” ê¶Œì¥ì‚¬í•­...")

    recommendations = [
        {
            "category": "íƒí—˜ ì „ëµ",
            "issue": "íƒí—˜ ë¶€ì¡±",
            "solution": "Target entropy = -1.25 (action_dim * 0.25)",
            "expected_improvement": "íƒí—˜ ë¹„ìœ¨ 0.87 â†’ 1.5+",
        },
        {
            "category": "ë³´ìƒ í•¨ìˆ˜",
            "issue": "ë³µí•© ë³´ìƒ ì‹ í˜¸ í˜¼ì¬",
            "solution": "ë‹¨ìˆœí™”ëœ Sharpe ratio ê¸°ë°˜ ë‹¨ì¼ ëª©ì  ìµœì í™”",
            "expected_improvement": "ë³´ìƒ í¸í–¥ì„± ê°ì†Œ",
        },
        {
            "category": "ìƒíƒœ ì •ê·œí™”",
            "issue": "ê³ ì°¨ì› ìƒíƒœê³µê°„",
            "solution": "Principal Component Analysis (PCA)ë¡œ ì°¨ì› ì¶•ì†Œ",
            "expected_improvement": "í•™ìŠµ ì´ˆê¸° ì•ˆì •ì„± í–¥ìƒ",
        },
        {
            "category": "ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°",
            "issue": "Dirichlet vs ì œì•½ ë¶ˆì¼ì¹˜",
            "solution": "Projected gradient ë˜ëŠ” Lagrange multiplier ì‚¬ìš©",
            "expected_improvement": "ì œì•½ ë§Œì¡±ë„ í–¥ìƒ",
        },
        {
            "category": "í•™ìŠµ íŒŒë¼ë¯¸í„°",
            "issue": "ë³´ìˆ˜ì  í•™ìŠµë¥ ",
            "solution": "Actor/Critic LR = 3e-4, ì ì‘ì  í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§",
            "expected_improvement": "ìˆ˜ë ´ ì†ë„ í–¥ìƒ",
        },
    ]

    print(f"  ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ë°©ì•ˆ:")
    for i, rec in enumerate(recommendations, 1):
        print(f"    {i}. [{rec['category']}] {rec['issue']}")
        print(f"       í•´ê²°ì±…: {rec['solution']}")
        print(f"       ì˜ˆìƒíš¨ê³¼: {rec['expected_improvement']}")

    analysis["recommendations"] = recommendations

    print("\n" + "=" * 80)
    print("SAC-í¬íŠ¸í´ë¦¬ì˜¤ ì í•©ì„± ë¶„ì„ ì™„ë£Œ")
    print("=" * 80)

    return analysis


def generate_optimization_config(analysis):
    """ìµœì í™”ëœ ì„¤ì • íŒŒì¼ ìƒì„±"""

    print("\n" + "=" * 60)
    print("ìµœì í™”ëœ ì„¤ì • ê¶Œì¥ì•ˆ")
    print("=" * 60)

    print(f"# config.py ìˆ˜ì • ê¶Œì¥ì‚¬í•­")
    print(f"")
    print(f"# í•™ìŠµë¥  ìµœì í™” (í˜„ì¬ë³´ë‹¤ 3ë°° ì¦ê°€)")
    print(f"ACTOR_LR = float(3e-4)  # í˜„ì¬: 1e-4")
    print(f"CRITIC_LR = float(3e-4)  # í˜„ì¬: 1e-4")
    print(f"ALPHA_LR = float(3e-4)   # í˜„ì¬: 1e-4")
    print(f"")
    print(f"# íƒ€ê²Ÿ ë„¤íŠ¸ì›Œí¬ ì—…ë°ì´íŠ¸ ë³´ìˆ˜ì  ì¡°ì •")
    print(f"TAU = float(0.001)       # í˜„ì¬: 0.005 (ë” ì•ˆì •ì )")
    print(f"")
    print(f"# ë°°ì¹˜ í¬ê¸° ê°ì†Œë¡œ ë” ë¹ ë¥¸ í•™ìŠµ")
    print(f"BATCH_SIZE = int(32)     # í˜„ì¬: 64")
    print(f"")
    print(f"# ì´ˆê¸° ê²½í—˜ ìˆ˜ì§‘ ê°•í™”")
    print(f"INITIAL_EXPLORATION_STEPS = int(1000)  # ì‹ ê·œ ì¶”ê°€")
    print(f"MIN_BUFFER_SIZE = int(500)             # ì‹ ê·œ ì¶”ê°€")

    print(f"\n# bcell.py ìˆ˜ì • ê¶Œì¥ì‚¬í•­")
    print(f"")
    print(f"# Target entropy ì¡°ì • (ë” ë§ì€ íƒí—˜)")
    print(f"self.target_entropy = -float(action_dim) * 0.25  # í˜„ì¬: 0.5")
    print(f"")
    print(f"# Concentration ìµœì†Œê°’ ì¦ê°€ (ì•ˆì •ì„±)")
    print(f"concentration = F.softplus(x_clamped) + 2.0  # í˜„ì¬: 1.0")

    print(f"\n# environment.py ìˆ˜ì • ê¶Œì¥ì‚¬í•­")
    print(f"")
    print(f"# Sharpe ìœˆë„ìš° ê°ì†Œ (ë¹ ë¥¸ í”¼ë“œë°±)")
    print(f"sharpe_window = 10  # í˜„ì¬: 20")
    print(f"")
    print(f"# ë³´ìƒ ë‹¨ìˆœí™”")
    print(f"final_reward = base_reward + sharpe_reward * 0.5  # ì§‘ì¤‘ë„ í˜ë„í‹° ì œê±°")

    print(f"\nğŸ¯ ì˜ˆìƒ ê°œì„  íš¨ê³¼:")
    print(f"   1. íƒí—˜ë¥  ì¦ê°€: 0.87 â†’ 1.5+")
    print(f"   2. í•™ìŠµ ì†ë„ í–¥ìƒ: 3ë°° ë¹ ë¥¸ ìˆ˜ë ´")
    print(f"   3. ì´ˆê¸° ì•ˆì •ì„± ê°œì„ : 1000 ìŠ¤í… ì›Œë°ì—…")
    print(f"   4. ë³´ìƒ ì‹ í˜¸ ê°œì„ : ë” ëª…í™•í•œ í”¼ë“œë°±")


if __name__ == "__main__":
    try:
        analysis = analyze_sac_portfolio_fit()
        generate_optimization_config(analysis)

        print(f"\nâœ… SACëŠ” í¬íŠ¸í´ë¦¬ì˜¤ í™˜ê²½ì— ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤!")
        print(f"   ì£¼ìš” ë¬¸ì œëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ í•´ê²° ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ ì í•©ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
